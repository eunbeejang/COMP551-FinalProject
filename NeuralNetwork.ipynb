{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Or any other X11 back-ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"stopwords\") # uncomment this line if you already have stopwords downloaded\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords = stopwords.words('english')\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "IMDB_train = pd.read_csv('./Dataset/Input/IMDB-train.txt', sep='\\t', encoding='latin-1', header=None)\n",
    "IMDB_train_y = IMDB_train[:][1]\n",
    "IMDB_valid = pd.read_csv('./Dataset/Input/IMDB-valid.txt', sep='\\t', encoding='latin-1', header=None)\n",
    "IMDB_valid_y = IMDB_valid[:][1]\n",
    "IMDB_test = pd.read_csv('./Dataset/Input/IMDB-test.txt', sep='\\t', encoding='latin-1', header=None)\n",
    "IMDB_test_y = IMDB_test[:][1]\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "print(\"Data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 2)\n",
      "(10000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(IMDB_train.shape)\n",
    "print(IMDB_valid.shape)\n",
    "print(IMDB_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [IMDB_train, IMDB_valid]\n",
    "frames_y = [IMDB_train_y, IMDB_valid_y]\n",
    "IMDB_train = pd.concat(frames)\n",
    "IMDB_train_y = pd.concat(frames_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(IMDB_train.shape)\n",
    "print(IMDB_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(IMDB_train_y.shape)\n",
    "print(IMDB_test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to remove words with low occurence from vocabulary\n",
    "\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function responsible for initial preprocessing: removal of HTML tags, punctuation, conversion to lowercase\n",
    "def preprocessing(data):\n",
    "    new_data = []\n",
    "    #i = 0\n",
    "    for sentence in (data[:][0]):\n",
    "        #clean = re.compile('<.*?>')\n",
    "        new_sentence = re.sub('<.*?>', '', sentence) # remove HTML tags\n",
    "        new_sentence = re.sub(r'[^\\w\\s]', '', new_sentence) # remove punctuation\n",
    "        new_sentence = new_sentence.lower() # convert to lower case\n",
    "        if new_sentence != '':\n",
    "            new_data.append(new_sentence)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain processed train and test\n",
    "\n",
    "IMDB_train = preprocessing(IMDB_train)\n",
    "IMDB_test = preprocessing(IMDB_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of n-gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# limit vocabulary to top 30,000 words to actaully be able to process data WITHOUT stop words\n",
    "unigram = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(1, 1), stop_words='english', max_features =30000)\n",
    "bigram = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(2, 2), stop_words='english', max_features =30000)\n",
    "trigram = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(3, 3), stop_words='english', max_features =30000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_gram = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(1, 3), stop_words='english', max_features =30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below loading n-gram representation w/o stop words (only relevant one is trigrams and all_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/sadhvi_mehta/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# comment out below two lines if you already have these downloaded\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "\n",
    "train_unigram = unigram.fit_transform(IMDB_train).toarray()\n",
    "test_unigram = unigram.transform(IMDB_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/sadhvi_mehta/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# comment out below two lines if you already have these downloaded\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "\n",
    "train_bigram = bigram.fit_transform(IMDB_train).toarray()\n",
    "test_bigram = bigram.transform(IMDB_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/sadhvi_mehta/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# comment out below two lines if you already have these downloaded\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "\n",
    "train_trigram = trigram.fit_transform(IMDB_train).toarray()\n",
    "test_trigram = trigram.transform(IMDB_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/sadhvi_mehta/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/sadhvi_mehta/anaconda3/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# comment out below two lines if you already have these downloaded\n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')\n",
    "\n",
    "train_allgram = all_gram.fit_transform(IMDB_train).toarray()\n",
    "test_allgram = all_gram.transform(IMDB_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below, loading n-gram representations w/ stop words (only relevant one is trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "unigram_w_sw = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(1, 1), stop_words=None, max_features =30000)\n",
    "bigram_w_sw = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(2, 2), stop_words=None, max_features =30000)\n",
    "trigram_w_sw = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=3, 3), stop_words=None, max_features =30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allgram_w_sw = CountVectorizer(tokenizer=LemmaTokenizer(), analyzer='word', ngram_range=(1, 3), stop_words=None, max_features =30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_unigram_w_sw = unigram_w_sw.fit_transform(IMDB_train).toarray()\n",
    "test_unigram_w_sw = unigram_w_sw.transform(IMDB_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bigram_w_sw = bigram_w_sw.fit_transform(IMDB_train).toarray()\n",
    "test_bigram_w_sw = bigram_w_sw.transform(IMDB_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_trigram_w_sw = trigram_w_sw.fit_transform(IMDB_train).toarray()\n",
    "test_trigram_w_sw = trigram_w_sw.transform(IMDB_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_allgram_w_sw = allgram_w_sw.fit_transform(IMDB_train).toarray()\n",
    "test_allgram_w_sw = allgram_w_sw.transform(IMDB_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that removes empty sentences\n",
    "\n",
    "def rm_sents(data, target):\n",
    "    new_data = []\n",
    "    new_target = []\n",
    "    for i in range(0,len(data)):\n",
    "        if len(list(set(data[i]))) is not 1:\n",
    "            new_data.append(data[i])\n",
    "            new_target.append(target[i])\n",
    "    return new_data, new_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to shuffle labels and data at same time\n",
    "import numpy as np\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    images = [a[i] for i in p]\n",
    "    lbls = [b.iloc[i] for i in p]\n",
    "    return images, lbls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Network Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import numpy as np\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# function that tries three different initializations of weights to get average performance\n",
    "def cv_model(epoch_num, x_arr, y_arr):\n",
    "    validation_scores = list()\n",
    "    for i in range(3):\n",
    "        model = baseline_model()\n",
    "        # fit network\n",
    "        history = model.fit(x_arr[:15000], y_arr[:15000], \n",
    "          validation_data=(x_arr[15000:], y_arr[15000:]), batch_size=200, epochs=epoch_num, verbose=0)\n",
    "        validation_scores.append(history.history['val_acc'][:-1])\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempted architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_shape=(30000,), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train trigram model w/o stopwords\n",
    "first_archi_tri_scores = cv_model(10, train_trigram, IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Architecture Trigram Scores:\n",
      "[0.7035999953746795, 0.7018999993801117, 0.7029999947547912]\n"
     ]
    }
   ],
   "source": [
    "print('First Architecture Trigram Scores:')\n",
    "temp = []\n",
    "for arr in first_archi_tri_scores:\n",
    "    temp.append(arr[8])\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train trigram (uni, bi, and tri) model w/o stopwords\n",
    "first_archi_all_scores = cv_model(10, train_allgram, IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Architecture Allgram Scores:\n",
      "[0.8874999964237213, 0.8879999959468842, 0.8879999935626983]\n"
     ]
    }
   ],
   "source": [
    "print('First Architecture Allgram Scores:')\n",
    "temp = []\n",
    "for arr in first_archi_all_scores:\n",
    "    temp.append(arr[8])\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train trigram model w/ stopwords\n",
    "first_archi_all_scores_sw = cv_model(10, train_allgram_w_sw, IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Architecture Allgram Scores W/ sw:\n",
      "[0.890799994468689, 0.8890999972820282, 0.8911999940872193]\n"
     ]
    }
   ],
   "source": [
    "print('First Architecture Allgram Scores W/ sw:')\n",
    "temp = []\n",
    "for arr in first_archi_all_scores_sw:\n",
    "    temp.append(arr[8])\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 11s - loss: 0.3808 - acc: 0.8487 - val_loss: 0.2892 - val_acc: 0.8891\n",
      "Epoch 2/10\n",
      " - 10s - loss: 0.1316 - acc: 0.9633 - val_loss: 0.2861 - val_acc: 0.8931\n",
      "Epoch 3/10\n",
      " - 10s - loss: 0.0603 - acc: 0.9907 - val_loss: 0.3087 - val_acc: 0.8917\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.0297 - acc: 0.9975 - val_loss: 0.3338 - val_acc: 0.8900\n",
      "Epoch 5/10\n",
      " - 10s - loss: 0.0168 - acc: 0.9995 - val_loss: 0.3567 - val_acc: 0.8897\n",
      "Epoch 6/10\n",
      " - 10s - loss: 0.0106 - acc: 0.9997 - val_loss: 0.3782 - val_acc: 0.8901\n",
      "Epoch 7/10\n",
      " - 10s - loss: 0.0073 - acc: 0.9999 - val_loss: 0.3954 - val_acc: 0.8886\n",
      "Epoch 8/10\n",
      " - 10s - loss: 0.0053 - acc: 0.9999 - val_loss: 0.4109 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      " - 10s - loss: 0.0040 - acc: 0.9999 - val_loss: 0.4248 - val_acc: 0.8884\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.0032 - acc: 0.9999 - val_loss: 0.4376 - val_acc: 0.8885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3a61bb198>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNIGRAM, BIGRAM, AND TRIGRAM\n",
    "\n",
    "# train trigram model w/o stop words\n",
    "allgram_model = baseline_model()\n",
    "allgram_model.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.3536 - acc: 0.8580 - val_loss: 0.2853 - val_acc: 0.8901\n",
      "Epoch 2/10\n",
      " - 8s - loss: 0.1077 - acc: 0.9720 - val_loss: 0.2887 - val_acc: 0.8935\n",
      "Epoch 3/10\n",
      " - 7s - loss: 0.0450 - acc: 0.9950 - val_loss: 0.3121 - val_acc: 0.8922\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.0198 - acc: 0.9992 - val_loss: 0.3418 - val_acc: 0.8925\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.0097 - acc: 0.9997 - val_loss: 0.3726 - val_acc: 0.8923\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.0060 - acc: 0.9997 - val_loss: 0.3928 - val_acc: 0.8916\n",
      "Epoch 7/10\n",
      " - 7s - loss: 0.0035 - acc: 0.9998 - val_loss: 0.4142 - val_acc: 0.8913\n",
      "Epoch 8/10\n",
      " - 7s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4318 - val_acc: 0.8912\n",
      "Epoch 9/10\n",
      " - 7s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4480 - val_acc: 0.8913\n",
      "Epoch 10/10\n",
      " - 7s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4606 - val_acc: 0.8906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc4d324f60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNIGRAM, BIGRAM, AND TRIGRAM\n",
    "\n",
    "# train trigram model w/ stop words\n",
    "allgram_sw_model = baseline_model()\n",
    "allgram_sw_model.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 0.4124 - acc: 0.8247 - val_loss: 0.3296 - val_acc: 0.8658\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.2854 - acc: 0.8885 - val_loss: 0.3318 - val_acc: 0.8691\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.2488 - acc: 0.9022 - val_loss: 0.3492 - val_acc: 0.8644\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.2280 - acc: 0.9107 - val_loss: 0.3581 - val_acc: 0.8643\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.2109 - acc: 0.9173 - val_loss: 0.3772 - val_acc: 0.8612\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.1957 - acc: 0.9242 - val_loss: 0.3847 - val_acc: 0.8576\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.1760 - acc: 0.9339 - val_loss: 0.4046 - val_acc: 0.8551\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.1550 - acc: 0.9401 - val_loss: 0.4313 - val_acc: 0.8525\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.1367 - acc: 0.9509 - val_loss: 0.4536 - val_acc: 0.8517\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.1204 - acc: 0.9571 - val_loss: 0.4917 - val_acc: 0.8465\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.1061 - acc: 0.9625 - val_loss: 0.5047 - val_acc: 0.8438\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0903 - acc: 0.9699 - val_loss: 0.5451 - val_acc: 0.8428\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0795 - acc: 0.9740 - val_loss: 0.5784 - val_acc: 0.8433\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0690 - acc: 0.9779 - val_loss: 0.6044 - val_acc: 0.8391\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0566 - acc: 0.9811 - val_loss: 0.6539 - val_acc: 0.8398\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0520 - acc: 0.9841 - val_loss: 0.6810 - val_acc: 0.8356\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0415 - acc: 0.9883 - val_loss: 0.7118 - val_acc: 0.8364\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0352 - acc: 0.9907 - val_loss: 0.7625 - val_acc: 0.8350\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0309 - acc: 0.9919 - val_loss: 0.7961 - val_acc: 0.8329\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0274 - acc: 0.9927 - val_loss: 0.8327 - val_acc: 0.8327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc42e021d0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNIGRAM, BIGRAM, AND TRIGRAM\n",
    "\n",
    "# train trigram model w/ stop words (and 20 epochs just for testing)\n",
    "bs = baseline_model()\n",
    "bs.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), batch_size=30, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attempted architecture: added dropout for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_shape=(30000,), activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-55bb5e8b01db>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-55bb5e8b01db>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    dropout_range = [0; 0.1; 0.2; 0.3]\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TRIGRAM:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import expon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# below, dictionary of params being modified\n",
    "dropout_range = [0, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(dropout_rate=dropout_range) \n",
    "\n",
    "# random search\n",
    "model = KerasClassifier(build_fn=baseline_model) \n",
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=3, n_iter=3)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(train_trigram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_trigram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=10, verbose=0)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 0.0749 - acc: 0.9488 - val_loss: 1.4123 - val_acc: 0.6787\n",
      "Epoch 2/10\n",
      " - 14s - loss: 0.0748 - acc: 0.9505 - val_loss: 1.4205 - val_acc: 0.6788\n",
      "Epoch 3/10\n",
      " - 14s - loss: 0.0748 - acc: 0.9493 - val_loss: 1.4290 - val_acc: 0.6791\n",
      "Epoch 4/10\n",
      " - 14s - loss: 0.0747 - acc: 0.9501 - val_loss: 1.4366 - val_acc: 0.6789\n",
      "Epoch 5/10\n",
      " - 14s - loss: 0.0748 - acc: 0.9483 - val_loss: 1.4447 - val_acc: 0.6797\n",
      "Epoch 6/10\n",
      " - 14s - loss: 0.0747 - acc: 0.9497 - val_loss: 1.4513 - val_acc: 0.6792\n",
      "Epoch 7/10\n",
      " - 12s - loss: 0.0747 - acc: 0.9487 - val_loss: 1.4584 - val_acc: 0.6785\n",
      "Epoch 8/10\n",
      " - 14s - loss: 0.0746 - acc: 0.9505 - val_loss: 1.4658 - val_acc: 0.6778\n",
      "Epoch 9/10\n",
      " - 13s - loss: 0.0743 - acc: 0.9506 - val_loss: 1.4728 - val_acc: 0.6784\n",
      "Epoch 10/10\n",
      " - 14s - loss: 0.0744 - acc: 0.9501 - val_loss: 1.4799 - val_acc: 0.6788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8bcee54a8>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train trigram model w/o stop words w/ best dropout\n",
    "trigram_model = baseline_model()\n",
    "trigram_model.fit(train_trigram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_trigram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadhvi_mehta/anaconda3/lib/python3.5/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 4 is smaller than n_iter=5. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4652 - acc: 0.7807 - val_loss: 0.4780 - val_acc: 0.7946\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.2121 - acc: 0.9419 - val_loss: 0.3504 - val_acc: 0.8624\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.1032 - acc: 0.9802 - val_loss: 0.4062 - val_acc: 0.8383\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.0494 - acc: 0.9956 - val_loss: 0.4273 - val_acc: 0.8447\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0237 - acc: 0.9987 - val_loss: 0.4723 - val_acc: 0.8422\n",
      "Epoch 6/20\n",
      " - 12s - loss: 0.0127 - acc: 0.9993 - val_loss: 0.4893 - val_acc: 0.8467\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0077 - acc: 0.9997 - val_loss: 0.5108 - val_acc: 0.8468\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0050 - acc: 0.9997 - val_loss: 0.5515 - val_acc: 0.8434\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0036 - acc: 0.9997 - val_loss: 0.5627 - val_acc: 0.8463\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0027 - acc: 0.9998 - val_loss: 0.5858 - val_acc: 0.8448\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0021 - acc: 0.9999 - val_loss: 0.6083 - val_acc: 0.8438\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.6288 - val_acc: 0.8424\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.6365 - val_acc: 0.8426\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6480 - val_acc: 0.8423\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6614 - val_acc: 0.8421\n",
      "Epoch 16/20\n",
      " - 11s - loss: 8.8002e-04 - acc: 1.0000 - val_loss: 0.6753 - val_acc: 0.8418\n",
      "Epoch 17/20\n",
      " - 11s - loss: 7.7986e-04 - acc: 1.0000 - val_loss: 0.6845 - val_acc: 0.8414\n",
      "Epoch 18/20\n",
      " - 11s - loss: 6.9918e-04 - acc: 1.0000 - val_loss: 0.6952 - val_acc: 0.8406\n",
      "Epoch 19/20\n",
      " - 11s - loss: 6.3423e-04 - acc: 1.0000 - val_loss: 0.7026 - val_acc: 0.8403\n",
      "Epoch 20/20\n",
      " - 11s - loss: 5.7055e-04 - acc: 1.0000 - val_loss: 0.7145 - val_acc: 0.8396\n",
      "5000/5000 [==============================] - 2s 496us/step\n",
      "10000/10000 [==============================] - 5s 470us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 9s - loss: 0.4293 - acc: 0.8340 - val_loss: 0.3089 - val_acc: 0.8798\n",
      "Epoch 2/20\n",
      " - 8s - loss: 0.1480 - acc: 0.9608 - val_loss: 0.2950 - val_acc: 0.8862\n",
      "Epoch 3/20\n",
      " - 8s - loss: 0.0679 - acc: 0.9893 - val_loss: 0.3074 - val_acc: 0.8854\n",
      "Epoch 4/20\n",
      " - 8s - loss: 0.0340 - acc: 0.9979 - val_loss: 0.3266 - val_acc: 0.8832\n",
      "Epoch 5/20\n",
      " - 8s - loss: 0.0198 - acc: 0.9996 - val_loss: 0.3446 - val_acc: 0.8817\n",
      "Epoch 6/20\n",
      " - 8s - loss: 0.0127 - acc: 0.9998 - val_loss: 0.3612 - val_acc: 0.8807\n",
      "Epoch 7/20\n",
      " - 8s - loss: 0.0089 - acc: 0.9999 - val_loss: 0.3760 - val_acc: 0.8802\n",
      "Epoch 8/20\n",
      " - 8s - loss: 0.0066 - acc: 0.9999 - val_loss: 0.3883 - val_acc: 0.8799\n",
      "Epoch 9/20\n",
      " - 9s - loss: 0.0051 - acc: 0.9998 - val_loss: 0.4018 - val_acc: 0.8788\n",
      "Epoch 10/20\n",
      " - 8s - loss: 0.0040 - acc: 0.9999 - val_loss: 0.4128 - val_acc: 0.8781\n",
      "Epoch 11/20\n",
      " - 9s - loss: 0.0032 - acc: 0.9999 - val_loss: 0.4226 - val_acc: 0.8778\n",
      "Epoch 12/20\n",
      " - 8s - loss: 0.0027 - acc: 0.9999 - val_loss: 0.4317 - val_acc: 0.8778\n",
      "Epoch 13/20\n",
      " - 8s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.4401 - val_acc: 0.8776\n",
      "Epoch 14/20\n",
      " - 8s - loss: 0.0019 - acc: 0.9999 - val_loss: 0.4483 - val_acc: 0.8769\n",
      "Epoch 15/20\n",
      " - 8s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.4557 - val_acc: 0.8765\n",
      "Epoch 16/20\n",
      " - 8s - loss: 0.0015 - acc: 0.9999 - val_loss: 0.4623 - val_acc: 0.8767\n",
      "Epoch 17/20\n",
      " - 8s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.4691 - val_acc: 0.8765\n",
      "Epoch 18/20\n",
      " - 8s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.4752 - val_acc: 0.8766\n",
      "Epoch 19/20\n",
      " - 8s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.4812 - val_acc: 0.8764\n",
      "Epoch 20/20\n",
      " - 8s - loss: 9.4812e-04 - acc: 0.9999 - val_loss: 0.4867 - val_acc: 0.8761\n",
      "5000/5000 [==============================] - 2s 403us/step\n",
      "10000/10000 [==============================] - 4s 350us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 11s - loss: 0.4444 - acc: 0.8154 - val_loss: 0.4121 - val_acc: 0.8226\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.1780 - acc: 0.9502 - val_loss: 0.3524 - val_acc: 0.8517\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.0761 - acc: 0.9858 - val_loss: 0.4315 - val_acc: 0.8348\n",
      "Epoch 4/20\n",
      " - 10s - loss: 0.0332 - acc: 0.9964 - val_loss: 0.4571 - val_acc: 0.8404\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0167 - acc: 0.9989 - val_loss: 0.4746 - val_acc: 0.8464\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0098 - acc: 0.9996 - val_loss: 0.5180 - val_acc: 0.8433\n",
      "Epoch 7/20\n",
      " - 10s - loss: 0.0063 - acc: 0.9998 - val_loss: 0.5455 - val_acc: 0.8430\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0045 - acc: 0.9999 - val_loss: 0.5704 - val_acc: 0.8429\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0033 - acc: 0.9999 - val_loss: 0.5901 - val_acc: 0.8431\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6135 - val_acc: 0.8421\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6361 - val_acc: 0.8407\n",
      "Epoch 12/20\n",
      " - 10s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6415 - val_acc: 0.8422\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6576 - val_acc: 0.8418\n",
      "Epoch 14/20\n",
      " - 12s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 0.8405\n",
      "Epoch 15/20\n",
      " - 11s - loss: 9.7653e-04 - acc: 1.0000 - val_loss: 0.6859 - val_acc: 0.8410\n",
      "Epoch 16/20\n",
      " - 11s - loss: 8.4259e-04 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.8400\n",
      "Epoch 17/20\n",
      " - 11s - loss: 7.3492e-04 - acc: 1.0000 - val_loss: 0.7121 - val_acc: 0.8403\n",
      "Epoch 18/20\n",
      " - 11s - loss: 6.4497e-04 - acc: 1.0000 - val_loss: 0.7241 - val_acc: 0.8395\n",
      "Epoch 19/20\n",
      " - 11s - loss: 5.7049e-04 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.8394\n",
      "Epoch 20/20\n",
      " - 11s - loss: 5.0809e-04 - acc: 1.0000 - val_loss: 0.7414 - val_acc: 0.8395\n",
      "5000/5000 [==============================] - 3s 506us/step\n",
      "10000/10000 [==============================] - 4s 446us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4759 - acc: 0.7560 - val_loss: 0.5517 - val_acc: 0.6959\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.2390 - acc: 0.9235 - val_loss: 0.3980 - val_acc: 0.8345\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.1125 - acc: 0.9768 - val_loss: 0.3976 - val_acc: 0.8443\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.0528 - acc: 0.9930 - val_loss: 0.4052 - val_acc: 0.8526\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0246 - acc: 0.9986 - val_loss: 0.4682 - val_acc: 0.8461\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0131 - acc: 0.9993 - val_loss: 0.5132 - val_acc: 0.8436\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0081 - acc: 0.9997 - val_loss: 0.5252 - val_acc: 0.8471\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0056 - acc: 0.9997 - val_loss: 0.5756 - val_acc: 0.8408\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0040 - acc: 0.9998 - val_loss: 0.5732 - val_acc: 0.8464\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0031 - acc: 0.9998 - val_loss: 0.5793 - val_acc: 0.8480\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.5994 - val_acc: 0.8472\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0020 - acc: 0.9999 - val_loss: 0.6314 - val_acc: 0.8432\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.6354 - val_acc: 0.8449\n",
      "Epoch 14/20\n",
      " - 12s - loss: 0.0015 - acc: 0.9999 - val_loss: 0.6414 - val_acc: 0.8457\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.6582 - val_acc: 0.8443\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.8449\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6684 - val_acc: 0.8453\n",
      "Epoch 18/20\n",
      " - 11s - loss: 8.8128e-04 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 0.8434\n",
      "Epoch 19/20\n",
      " - 11s - loss: 8.0947e-04 - acc: 1.0000 - val_loss: 0.6939 - val_acc: 0.8437\n",
      "Epoch 20/20\n",
      " - 11s - loss: 7.3113e-04 - acc: 1.0000 - val_loss: 0.7055 - val_acc: 0.8426\n",
      "5000/5000 [==============================] - 3s 691us/step\n",
      "10000/10000 [==============================] - 6s 561us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4430 - acc: 0.8194 - val_loss: 0.3147 - val_acc: 0.8783\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.1604 - acc: 0.9564 - val_loss: 0.2958 - val_acc: 0.8854\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.0774 - acc: 0.9879 - val_loss: 0.3066 - val_acc: 0.8869\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.0408 - acc: 0.9967 - val_loss: 0.3252 - val_acc: 0.8838\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0238 - acc: 0.9989 - val_loss: 0.3427 - val_acc: 0.8819\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0157 - acc: 0.9995 - val_loss: 0.3611 - val_acc: 0.8801\n",
      "Epoch 7/20\n",
      " - 12s - loss: 0.0107 - acc: 0.9999 - val_loss: 0.3758 - val_acc: 0.8790\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0078 - acc: 0.9999 - val_loss: 0.3890 - val_acc: 0.8788\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.4028 - val_acc: 0.8773\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.4127 - val_acc: 0.8774\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4223 - val_acc: 0.8775\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4321 - val_acc: 0.8774\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4404 - val_acc: 0.8772\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4485 - val_acc: 0.8776\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4558 - val_acc: 0.8776\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4631 - val_acc: 0.8773\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.8774\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4757 - val_acc: 0.8777\n",
      "Epoch 19/20\n",
      " - 11s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4835 - val_acc: 0.8770\n",
      "Epoch 20/20\n",
      " - 11s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.4900 - val_acc: 0.8764\n",
      "5000/5000 [==============================] - 2s 452us/step\n",
      "10000/10000 [==============================] - 4s 434us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4617 - acc: 0.8024 - val_loss: 0.4520 - val_acc: 0.8050\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.2008 - acc: 0.9429 - val_loss: 0.4137 - val_acc: 0.8206\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.0914 - acc: 0.9819 - val_loss: 0.3953 - val_acc: 0.8459\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.0413 - acc: 0.9948 - val_loss: 0.4418 - val_acc: 0.8443\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0206 - acc: 0.9987 - val_loss: 0.4803 - val_acc: 0.8439\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0113 - acc: 0.9996 - val_loss: 0.5162 - val_acc: 0.8437\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0071 - acc: 0.9998 - val_loss: 0.5635 - val_acc: 0.8398\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0049 - acc: 0.9999 - val_loss: 0.5703 - val_acc: 0.8433\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6002 - val_acc: 0.8413\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.6150 - val_acc: 0.8426\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.8400\n",
      "Epoch 12/20\n",
      " - 10s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6558 - val_acc: 0.8416\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.8403\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6876 - val_acc: 0.8402\n",
      "Epoch 15/20\n",
      " - 12s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7117 - val_acc: 0.8385\n",
      "Epoch 16/20\n",
      " - 11s - loss: 8.8682e-04 - acc: 1.0000 - val_loss: 0.7142 - val_acc: 0.8401\n",
      "Epoch 17/20\n",
      " - 10s - loss: 7.6836e-04 - acc: 1.0000 - val_loss: 0.7211 - val_acc: 0.8393\n",
      "Epoch 18/20\n",
      " - 10s - loss: 6.7782e-04 - acc: 1.0000 - val_loss: 0.7458 - val_acc: 0.8384\n",
      "Epoch 19/20\n",
      " - 10s - loss: 5.8961e-04 - acc: 1.0000 - val_loss: 0.7423 - val_acc: 0.8400\n",
      "Epoch 20/20\n",
      " - 11s - loss: 5.0910e-04 - acc: 1.0000 - val_loss: 0.7632 - val_acc: 0.8382\n",
      "5000/5000 [==============================] - 2s 488us/step\n",
      "10000/10000 [==============================] - 4s 439us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 11s - loss: 0.4705 - acc: 0.7874 - val_loss: 0.4526 - val_acc: 0.8099\n",
      "Epoch 2/20\n",
      " - 10s - loss: 0.2192 - acc: 0.9330 - val_loss: 0.3687 - val_acc: 0.8513\n",
      "Epoch 3/20\n",
      " - 10s - loss: 0.1080 - acc: 0.9744 - val_loss: 0.3826 - val_acc: 0.8527\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.0522 - acc: 0.9938 - val_loss: 0.4211 - val_acc: 0.8489\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0275 - acc: 0.9980 - val_loss: 0.4760 - val_acc: 0.8440\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0164 - acc: 0.9994 - val_loss: 0.5041 - val_acc: 0.8438\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0101 - acc: 0.9997 - val_loss: 0.5182 - val_acc: 0.8463\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0073 - acc: 0.9998 - val_loss: 0.5193 - val_acc: 0.8508\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0053 - acc: 0.9998 - val_loss: 0.5723 - val_acc: 0.8432\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0039 - acc: 0.9998 - val_loss: 0.5813 - val_acc: 0.8451\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0032 - acc: 0.9999 - val_loss: 0.6018 - val_acc: 0.8437\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0027 - acc: 0.9999 - val_loss: 0.6010 - val_acc: 0.8449\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.6233 - val_acc: 0.8440\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6517 - val_acc: 0.8414\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 0.8459\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.8454\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6608 - val_acc: 0.8458\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6785 - val_acc: 0.8448\n",
      "Epoch 19/20\n",
      " - 11s - loss: 9.5316e-04 - acc: 1.0000 - val_loss: 0.6902 - val_acc: 0.8440\n",
      "Epoch 20/20\n",
      " - 11s - loss: 9.1772e-04 - acc: 1.0000 - val_loss: 0.6906 - val_acc: 0.8461\n",
      "5000/5000 [==============================] - 3s 520us/step\n",
      "10000/10000 [==============================] - 5s 481us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 10s - loss: 0.4373 - acc: 0.8186 - val_loss: 0.3140 - val_acc: 0.8788\n",
      "Epoch 2/20\n",
      " - 8s - loss: 0.1614 - acc: 0.9573 - val_loss: 0.2981 - val_acc: 0.8842\n",
      "Epoch 3/20\n",
      " - 8s - loss: 0.0815 - acc: 0.9857 - val_loss: 0.3105 - val_acc: 0.8857\n",
      "Epoch 4/20\n",
      " - 8s - loss: 0.0449 - acc: 0.9954 - val_loss: 0.3245 - val_acc: 0.8831\n",
      "Epoch 5/20\n",
      " - 8s - loss: 0.0263 - acc: 0.9985 - val_loss: 0.3456 - val_acc: 0.8826\n",
      "Epoch 6/20\n",
      " - 8s - loss: 0.0169 - acc: 0.9995 - val_loss: 0.3646 - val_acc: 0.8800\n",
      "Epoch 7/20\n",
      " - 8s - loss: 0.0116 - acc: 0.9997 - val_loss: 0.3797 - val_acc: 0.8799\n",
      "Epoch 8/20\n",
      " - 8s - loss: 0.0089 - acc: 0.9999 - val_loss: 0.3949 - val_acc: 0.8799\n",
      "Epoch 9/20\n",
      " - 8s - loss: 0.0068 - acc: 0.9999 - val_loss: 0.4071 - val_acc: 0.8781\n",
      "Epoch 10/20\n",
      " - 8s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.4217 - val_acc: 0.8783\n",
      "Epoch 11/20\n",
      " - 8s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4326 - val_acc: 0.8776\n",
      "Epoch 12/20\n",
      " - 8s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.4418 - val_acc: 0.8768\n",
      "Epoch 13/20\n",
      " - 8s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4504 - val_acc: 0.8779\n",
      "Epoch 14/20\n",
      " - 8s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4591 - val_acc: 0.8752\n",
      "Epoch 15/20\n",
      " - 8s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.4672 - val_acc: 0.8766\n",
      "Epoch 16/20\n",
      " - 8s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4745 - val_acc: 0.8756\n",
      "Epoch 17/20\n",
      " - 8s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8760\n",
      "Epoch 18/20\n",
      " - 8s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8757\n",
      "Epoch 19/20\n",
      " - 8s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.4947 - val_acc: 0.8755\n",
      "Epoch 20/20\n",
      " - 8s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.8756\n",
      "5000/5000 [==============================] - 2s 372us/step\n",
      "10000/10000 [==============================] - 4s 356us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4681 - acc: 0.7723 - val_loss: 0.5237 - val_acc: 0.7451\n",
      "Epoch 2/20\n",
      " - 10s - loss: 0.2251 - acc: 0.9328 - val_loss: 0.4108 - val_acc: 0.8218\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.1035 - acc: 0.9745 - val_loss: 0.4156 - val_acc: 0.8367\n",
      "Epoch 4/20\n",
      " - 12s - loss: 0.0467 - acc: 0.9939 - val_loss: 0.4388 - val_acc: 0.8446\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0241 - acc: 0.9982 - val_loss: 0.4898 - val_acc: 0.8394\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0144 - acc: 0.9992 - val_loss: 0.5252 - val_acc: 0.8395\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0094 - acc: 0.9997 - val_loss: 0.5430 - val_acc: 0.8415\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0064 - acc: 0.9999 - val_loss: 0.5556 - val_acc: 0.8435\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0048 - acc: 0.9998 - val_loss: 0.5948 - val_acc: 0.8414\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0041 - acc: 0.9998 - val_loss: 0.6086 - val_acc: 0.8414\n",
      "Epoch 11/20\n",
      " - 13s - loss: 0.0032 - acc: 0.9999 - val_loss: 0.6460 - val_acc: 0.8390\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.6534 - val_acc: 0.8419\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6634 - val_acc: 0.8419\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6604 - val_acc: 0.8443\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6987 - val_acc: 0.8397\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6907 - val_acc: 0.8418\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.7093 - val_acc: 0.8401\n",
      "Epoch 18/20\n",
      " - 11s - loss: 9.2117e-04 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.8407\n",
      "Epoch 19/20\n",
      " - 11s - loss: 8.7354e-04 - acc: 1.0000 - val_loss: 0.7444 - val_acc: 0.8395\n",
      "Epoch 20/20\n",
      " - 11s - loss: 7.6668e-04 - acc: 1.0000 - val_loss: 0.7608 - val_acc: 0.8384\n",
      "5000/5000 [==============================] - 2s 474us/step\n",
      "10000/10000 [==============================] - 5s 463us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4801 - acc: 0.7648 - val_loss: 0.5256 - val_acc: 0.7399\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.2499 - acc: 0.9174 - val_loss: 0.3936 - val_acc: 0.8380\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.1294 - acc: 0.9664 - val_loss: 0.3604 - val_acc: 0.8591\n",
      "Epoch 4/20\n",
      " - 10s - loss: 0.0626 - acc: 0.9894 - val_loss: 0.4348 - val_acc: 0.8441\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0332 - acc: 0.9971 - val_loss: 0.4656 - val_acc: 0.8469\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0192 - acc: 0.9986 - val_loss: 0.4808 - val_acc: 0.8484\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0120 - acc: 0.9995 - val_loss: 0.5200 - val_acc: 0.8440\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0085 - acc: 0.9997 - val_loss: 0.5424 - val_acc: 0.8440\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0065 - acc: 0.9996 - val_loss: 0.5797 - val_acc: 0.8424\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0051 - acc: 0.9996 - val_loss: 0.5605 - val_acc: 0.8476\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0040 - acc: 0.9998 - val_loss: 0.5932 - val_acc: 0.8452\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0033 - acc: 0.9998 - val_loss: 0.5986 - val_acc: 0.8469\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0026 - acc: 0.9999 - val_loss: 0.6227 - val_acc: 0.8461\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0022 - acc: 0.9999 - val_loss: 0.6353 - val_acc: 0.8452\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0020 - acc: 0.9999 - val_loss: 0.6447 - val_acc: 0.8466\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6644 - val_acc: 0.8451\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6650 - val_acc: 0.8462\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 0.8462\n",
      "Epoch 19/20\n",
      " - 11s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6714 - val_acc: 0.8484\n",
      "Epoch 20/20\n",
      " - 11s - loss: 0.0011 - acc: 0.9999 - val_loss: 0.6504 - val_acc: 0.8530\n",
      "5000/5000 [==============================] - 3s 523us/step\n",
      "10000/10000 [==============================] - 5s 476us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4535 - acc: 0.8142 - val_loss: 0.3261 - val_acc: 0.8752\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.1841 - acc: 0.9466 - val_loss: 0.2938 - val_acc: 0.8863\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.0968 - acc: 0.9811 - val_loss: 0.3023 - val_acc: 0.8861\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.0546 - acc: 0.9937 - val_loss: 0.3183 - val_acc: 0.8837\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0332 - acc: 0.9973 - val_loss: 0.3380 - val_acc: 0.8826\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0225 - acc: 0.9987 - val_loss: 0.3552 - val_acc: 0.8807\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0164 - acc: 0.9995 - val_loss: 0.3760 - val_acc: 0.8798\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0111 - acc: 0.9998 - val_loss: 0.3899 - val_acc: 0.8795\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0091 - acc: 0.9995 - val_loss: 0.4042 - val_acc: 0.8793\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0072 - acc: 0.9998 - val_loss: 0.4160 - val_acc: 0.8790\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0059 - acc: 0.9999 - val_loss: 0.4279 - val_acc: 0.8794\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0046 - acc: 0.9999 - val_loss: 0.4379 - val_acc: 0.8781\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0040 - acc: 0.9999 - val_loss: 0.4469 - val_acc: 0.8796\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0033 - acc: 0.9999 - val_loss: 0.4554 - val_acc: 0.8790\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0028 - acc: 0.9999 - val_loss: 0.4632 - val_acc: 0.8788\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0026 - acc: 0.9999 - val_loss: 0.4716 - val_acc: 0.8768\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0022 - acc: 0.9999 - val_loss: 0.4818 - val_acc: 0.8761\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.0021 - acc: 0.9999 - val_loss: 0.4872 - val_acc: 0.8770\n",
      "Epoch 19/20\n",
      " - 11s - loss: 0.0019 - acc: 0.9999 - val_loss: 0.4968 - val_acc: 0.8751\n",
      "Epoch 20/20\n",
      " - 11s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.5007 - val_acc: 0.8756\n",
      "5000/5000 [==============================] - 2s 449us/step\n",
      "10000/10000 [==============================] - 5s 476us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 12s - loss: 0.4263 - acc: 0.8277 - val_loss: 0.4170 - val_acc: 0.8247\n",
      "Epoch 2/20\n",
      " - 11s - loss: 0.1826 - acc: 0.9476 - val_loss: 0.3914 - val_acc: 0.8357\n",
      "Epoch 3/20\n",
      " - 11s - loss: 0.0931 - acc: 0.9792 - val_loss: 0.4071 - val_acc: 0.8448\n",
      "Epoch 4/20\n",
      " - 11s - loss: 0.0493 - acc: 0.9926 - val_loss: 0.4669 - val_acc: 0.8392\n",
      "Epoch 5/20\n",
      " - 11s - loss: 0.0281 - acc: 0.9965 - val_loss: 0.4845 - val_acc: 0.8462\n",
      "Epoch 6/20\n",
      " - 11s - loss: 0.0166 - acc: 0.9990 - val_loss: 0.5050 - val_acc: 0.8483\n",
      "Epoch 7/20\n",
      " - 11s - loss: 0.0104 - acc: 0.9995 - val_loss: 0.5548 - val_acc: 0.8436\n",
      "Epoch 8/20\n",
      " - 11s - loss: 0.0073 - acc: 0.9997 - val_loss: 0.5855 - val_acc: 0.8420\n",
      "Epoch 9/20\n",
      " - 11s - loss: 0.0057 - acc: 0.9997 - val_loss: 0.5992 - val_acc: 0.8424\n",
      "Epoch 10/20\n",
      " - 11s - loss: 0.0044 - acc: 0.9999 - val_loss: 0.6246 - val_acc: 0.8427\n",
      "Epoch 11/20\n",
      " - 11s - loss: 0.0037 - acc: 0.9998 - val_loss: 0.6417 - val_acc: 0.8418\n",
      "Epoch 12/20\n",
      " - 11s - loss: 0.0031 - acc: 0.9999 - val_loss: 0.6550 - val_acc: 0.8430\n",
      "Epoch 13/20\n",
      " - 11s - loss: 0.0026 - acc: 0.9998 - val_loss: 0.6386 - val_acc: 0.8474\n",
      "Epoch 14/20\n",
      " - 11s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.6847 - val_acc: 0.8407\n",
      "Epoch 15/20\n",
      " - 11s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6764 - val_acc: 0.8444\n",
      "Epoch 16/20\n",
      " - 11s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6944 - val_acc: 0.8433\n",
      "Epoch 17/20\n",
      " - 11s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7026 - val_acc: 0.8437\n",
      "Epoch 18/20\n",
      " - 11s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.7106 - val_acc: 0.8443\n",
      "Epoch 19/20\n",
      " - 11s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.7362 - val_acc: 0.8407\n",
      "Epoch 20/20\n",
      " - 11s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7250 - val_acc: 0.8432\n",
      "5000/5000 [==============================] - 2s 481us/step\n",
      "10000/10000 [==============================] - 4s 435us/step\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 16s - loss: 0.4134 - acc: 0.8337 - val_loss: 0.2909 - val_acc: 0.8919\n",
      "Epoch 2/20\n",
      " - 15s - loss: 0.1713 - acc: 0.9483 - val_loss: 0.2764 - val_acc: 0.8937\n",
      "Epoch 3/20\n",
      " - 15s - loss: 0.0896 - acc: 0.9791 - val_loss: 0.2920 - val_acc: 0.8925\n",
      "Epoch 4/20\n",
      " - 15s - loss: 0.0489 - acc: 0.9922 - val_loss: 0.3170 - val_acc: 0.8917\n",
      "Epoch 5/20\n",
      " - 14s - loss: 0.0296 - acc: 0.9965 - val_loss: 0.3389 - val_acc: 0.8911\n",
      "Epoch 6/20\n",
      " - 15s - loss: 0.0194 - acc: 0.9985 - val_loss: 0.3623 - val_acc: 0.8896\n",
      "Epoch 7/20\n",
      " - 15s - loss: 0.0133 - acc: 0.9994 - val_loss: 0.3857 - val_acc: 0.8904\n",
      "Epoch 8/20\n",
      " - 15s - loss: 0.0095 - acc: 0.9997 - val_loss: 0.4036 - val_acc: 0.8880\n",
      "Epoch 9/20\n",
      " - 15s - loss: 0.0077 - acc: 0.9995 - val_loss: 0.4190 - val_acc: 0.8868\n",
      "Epoch 10/20\n",
      " - 15s - loss: 0.0057 - acc: 0.9998 - val_loss: 0.4326 - val_acc: 0.8868\n",
      "Epoch 11/20\n",
      " - 15s - loss: 0.0044 - acc: 0.9999 - val_loss: 0.4476 - val_acc: 0.8873\n",
      "Epoch 12/20\n",
      " - 15s - loss: 0.0037 - acc: 0.9999 - val_loss: 0.4600 - val_acc: 0.8876\n",
      "Epoch 13/20\n",
      " - 15s - loss: 0.0033 - acc: 0.9999 - val_loss: 0.4716 - val_acc: 0.8869\n",
      "Epoch 14/20\n",
      " - 15s - loss: 0.0028 - acc: 0.9999 - val_loss: 0.4829 - val_acc: 0.8877\n",
      "Epoch 15/20\n",
      " - 15s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4916 - val_acc: 0.8872\n",
      "Epoch 16/20\n",
      " - 15s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4999 - val_acc: 0.8875\n",
      "Epoch 17/20\n",
      " - 15s - loss: 0.0018 - acc: 0.9999 - val_loss: 0.5081 - val_acc: 0.8871\n",
      "Epoch 18/20\n",
      " - 15s - loss: 0.0016 - acc: 0.9999 - val_loss: 0.5171 - val_acc: 0.8861\n",
      "Epoch 19/20\n",
      " - 15s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.5243 - val_acc: 0.8860\n",
      "Epoch 20/20\n",
      " - 15s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.5303 - val_acc: 0.8857\n",
      "Best: 0.784267 using {'dropout_rate': 0.3, 'epochs': 10, 'batch_size': 200}\n",
      "Execution time: 2963.3923630714417 ms\n"
     ]
    }
   ],
   "source": [
    "# ALLGRAM:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import expon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# below, dictionary of params being modified\n",
    "dropout_range = [0, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(dropout_rate=dropout_range, epochs=[10], batch_size=[200]) \n",
    "\n",
    "# random search\n",
    "model = KerasClassifier(build_fn=baseline_model) \n",
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=3, n_iter=4)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_dropout = random_result.best_params_['dropout_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 0.4047 - acc: 0.8385 - val_loss: 0.2950 - val_acc: 0.8890\n",
      "Epoch 2/20\n",
      " - 15s - loss: 0.1579 - acc: 0.9549 - val_loss: 0.2876 - val_acc: 0.8895\n",
      "Epoch 3/20\n",
      " - 14s - loss: 0.0806 - acc: 0.9826 - val_loss: 0.3055 - val_acc: 0.8880\n",
      "Epoch 4/20\n",
      " - 13s - loss: 0.0441 - acc: 0.9947 - val_loss: 0.3315 - val_acc: 0.8850\n",
      "Epoch 5/20\n",
      " - 13s - loss: 0.0258 - acc: 0.9982 - val_loss: 0.3554 - val_acc: 0.8842\n",
      "Epoch 6/20\n",
      " - 13s - loss: 0.0170 - acc: 0.9993 - val_loss: 0.3803 - val_acc: 0.8860\n",
      "Epoch 7/20\n",
      " - 13s - loss: 0.0116 - acc: 0.9997 - val_loss: 0.4004 - val_acc: 0.8859\n",
      "Epoch 8/20\n",
      " - 12s - loss: 0.0087 - acc: 0.9998 - val_loss: 0.4191 - val_acc: 0.8841\n",
      "Epoch 9/20\n",
      " - 12s - loss: 0.0068 - acc: 0.9998 - val_loss: 0.4355 - val_acc: 0.8833\n",
      "Epoch 10/20\n",
      " - 12s - loss: 0.0053 - acc: 0.9999 - val_loss: 0.4576 - val_acc: 0.8796\n",
      "Epoch 11/20\n",
      " - 13s - loss: 0.0042 - acc: 0.9999 - val_loss: 0.4715 - val_acc: 0.8817\n",
      "Epoch 12/20\n",
      " - 13s - loss: 0.0038 - acc: 0.9999 - val_loss: 0.4813 - val_acc: 0.8818\n",
      "Epoch 13/20\n",
      " - 13s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4915 - val_acc: 0.8827\n",
      "Epoch 14/20\n",
      " - 15s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.5031 - val_acc: 0.8802\n",
      "Epoch 15/20\n",
      " - 14s - loss: 0.0021 - acc: 0.9999 - val_loss: 0.5115 - val_acc: 0.8805\n",
      "Epoch 16/20\n",
      " - 14s - loss: 0.0021 - acc: 0.9999 - val_loss: 0.5224 - val_acc: 0.8801\n",
      "Epoch 17/20\n",
      " - 14s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5321 - val_acc: 0.8801\n",
      "Epoch 18/20\n",
      " - 15s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5383 - val_acc: 0.8806\n",
      "Epoch 19/20\n",
      " - 15s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5427 - val_acc: 0.8803\n",
      "Epoch 20/20\n",
      " - 15s - loss: 0.0013 - acc: 0.9999 - val_loss: 0.5493 - val_acc: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c5ec9b748>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train allgram model (uni, bi, tri) w/o stop words w/ best dropout\n",
    "allgram_model = baseline_model(best_dropout)\n",
    "allgram_model.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = allgram_model.evaluate(test_allgram, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.6158240246343613\n",
      "Test accuracy:  0.86176\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 0.3756 - acc: 0.8511 - val_loss: 0.3164 - val_acc: 0.8785\n",
      "Epoch 2/20\n",
      " - 16s - loss: 0.0870 - acc: 0.9760 - val_loss: 0.4537 - val_acc: 0.8387\n",
      "Epoch 3/20\n",
      " - 16s - loss: 0.0223 - acc: 0.9980 - val_loss: 0.4925 - val_acc: 0.8492\n",
      "Epoch 4/20\n",
      " - 16s - loss: 0.0070 - acc: 0.9997 - val_loss: 0.5528 - val_acc: 0.8484\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0032 - acc: 0.9998 - val_loss: 0.5629 - val_acc: 0.8544\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.6275 - val_acc: 0.8513\n",
      "Epoch 7/20\n",
      " - 17s - loss: 9.5332e-04 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 0.8481\n",
      "Epoch 8/20\n",
      " - 17s - loss: 6.1358e-04 - acc: 1.0000 - val_loss: 0.6814 - val_acc: 0.8505\n",
      "Epoch 9/20\n",
      " - 17s - loss: 4.2970e-04 - acc: 1.0000 - val_loss: 0.6992 - val_acc: 0.8512\n",
      "Epoch 10/20\n",
      " - 17s - loss: 3.1995e-04 - acc: 1.0000 - val_loss: 0.7238 - val_acc: 0.8505\n",
      "Epoch 11/20\n",
      " - 17s - loss: 2.4431e-04 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.8492\n",
      "Epoch 12/20\n",
      " - 17s - loss: 1.9575e-04 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 0.8496\n",
      "Epoch 13/20\n",
      " - 17s - loss: 1.5884e-04 - acc: 1.0000 - val_loss: 0.7747 - val_acc: 0.8491\n",
      "Epoch 14/20\n",
      " - 17s - loss: 1.3222e-04 - acc: 1.0000 - val_loss: 0.7946 - val_acc: 0.8477\n",
      "Epoch 15/20\n",
      " - 17s - loss: 1.1205e-04 - acc: 1.0000 - val_loss: 0.7931 - val_acc: 0.8488\n",
      "Epoch 16/20\n",
      " - 17s - loss: 9.5806e-05 - acc: 1.0000 - val_loss: 0.8108 - val_acc: 0.8477\n",
      "Epoch 17/20\n",
      " - 20s - loss: 8.3379e-05 - acc: 1.0000 - val_loss: 0.8129 - val_acc: 0.8484\n",
      "Epoch 18/20\n",
      " - 17s - loss: 7.2696e-05 - acc: 1.0000 - val_loss: 0.8262 - val_acc: 0.8484\n",
      "Epoch 19/20\n",
      " - 17s - loss: 6.3929e-05 - acc: 1.0000 - val_loss: 0.8325 - val_acc: 0.8483\n",
      "Epoch 20/20\n",
      " - 17s - loss: 5.6474e-05 - acc: 1.0000 - val_loss: 0.8387 - val_acc: 0.8484\n",
      "5000/5000 [==============================] - 2s 466us/step\n",
      "10000/10000 [==============================] - 5s 470us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 17s - loss: 0.3777 - acc: 0.8364 - val_loss: 0.2974 - val_acc: 0.8844\n",
      "Epoch 2/20\n",
      " - 17s - loss: 0.0665 - acc: 0.9825 - val_loss: 0.3354 - val_acc: 0.8850\n",
      "Epoch 3/20\n",
      " - 16s - loss: 0.0142 - acc: 0.9990 - val_loss: 0.3876 - val_acc: 0.8852\n",
      "Epoch 4/20\n",
      " - 16s - loss: 0.0050 - acc: 0.9997 - val_loss: 0.4271 - val_acc: 0.8859\n",
      "Epoch 5/20\n",
      " - 16s - loss: 0.0028 - acc: 0.9998 - val_loss: 0.4536 - val_acc: 0.8847\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0011 - acc: 0.9999 - val_loss: 0.4715 - val_acc: 0.8858\n",
      "Epoch 7/20\n",
      " - 16s - loss: 6.6609e-04 - acc: 1.0000 - val_loss: 0.4880 - val_acc: 0.8861\n",
      "Epoch 8/20\n",
      " - 17s - loss: 4.1948e-04 - acc: 1.0000 - val_loss: 0.5043 - val_acc: 0.8847\n",
      "Epoch 9/20\n",
      " - 16s - loss: 2.9829e-04 - acc: 1.0000 - val_loss: 0.5164 - val_acc: 0.8853\n",
      "Epoch 10/20\n",
      " - 16s - loss: 2.2356e-04 - acc: 1.0000 - val_loss: 0.5283 - val_acc: 0.8842\n",
      "Epoch 11/20\n",
      " - 16s - loss: 1.7339e-04 - acc: 1.0000 - val_loss: 0.5380 - val_acc: 0.8841\n",
      "Epoch 12/20\n",
      " - 16s - loss: 1.3814e-04 - acc: 1.0000 - val_loss: 0.5466 - val_acc: 0.8844\n",
      "Epoch 13/20\n",
      " - 16s - loss: 1.1274e-04 - acc: 1.0000 - val_loss: 0.5553 - val_acc: 0.8841\n",
      "Epoch 14/20\n",
      " - 16s - loss: 9.3650e-05 - acc: 1.0000 - val_loss: 0.5623 - val_acc: 0.8841\n",
      "Epoch 15/20\n",
      " - 16s - loss: 7.9046e-05 - acc: 1.0000 - val_loss: 0.5694 - val_acc: 0.8838\n",
      "Epoch 16/20\n",
      " - 17s - loss: 6.7419e-05 - acc: 1.0000 - val_loss: 0.5757 - val_acc: 0.8836\n",
      "Epoch 17/20\n",
      " - 17s - loss: 5.8129e-05 - acc: 1.0000 - val_loss: 0.5816 - val_acc: 0.8834\n",
      "Epoch 18/20\n",
      " - 16s - loss: 5.0689e-05 - acc: 1.0000 - val_loss: 0.5873 - val_acc: 0.8833\n",
      "Epoch 19/20\n",
      " - 17s - loss: 4.4508e-05 - acc: 1.0000 - val_loss: 0.5928 - val_acc: 0.8827\n",
      "Epoch 20/20\n",
      " - 16s - loss: 3.9371e-05 - acc: 1.0000 - val_loss: 0.5977 - val_acc: 0.8831\n",
      "5000/5000 [==============================] - 2s 458us/step\n",
      "10000/10000 [==============================] - 5s 459us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 0.3569 - acc: 0.8626 - val_loss: 0.3925 - val_acc: 0.8413\n",
      "Epoch 2/20\n",
      " - 19s - loss: 0.0684 - acc: 0.9827 - val_loss: 0.3799 - val_acc: 0.8687\n",
      "Epoch 3/20\n",
      " - 19s - loss: 0.0172 - acc: 0.9988 - val_loss: 0.5365 - val_acc: 0.8476\n",
      "Epoch 4/20\n",
      " - 19s - loss: 0.0049 - acc: 0.9999 - val_loss: 0.6126 - val_acc: 0.8450\n",
      "Epoch 5/20\n",
      " - 19s - loss: 0.0022 - acc: 0.9999 - val_loss: 0.6396 - val_acc: 0.8479\n",
      "Epoch 6/20\n",
      " - 19s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.6625 - val_acc: 0.8499\n",
      "Epoch 7/20\n",
      " - 19s - loss: 7.4805e-04 - acc: 0.9999 - val_loss: 0.6968 - val_acc: 0.8498\n",
      "Epoch 8/20\n",
      " - 19s - loss: 4.9890e-04 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 0.8473\n",
      "Epoch 9/20\n",
      " - 19s - loss: 3.5275e-04 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.8462\n",
      "Epoch 10/20\n",
      " - 19s - loss: 2.6013e-04 - acc: 1.0000 - val_loss: 0.7832 - val_acc: 0.8456\n",
      "Epoch 11/20\n",
      " - 19s - loss: 1.9923e-04 - acc: 1.0000 - val_loss: 0.7975 - val_acc: 0.8455\n",
      "Epoch 12/20\n",
      " - 19s - loss: 1.5758e-04 - acc: 1.0000 - val_loss: 0.8236 - val_acc: 0.8444\n",
      "Epoch 13/20\n",
      " - 19s - loss: 1.2688e-04 - acc: 1.0000 - val_loss: 0.8317 - val_acc: 0.8455\n",
      "Epoch 14/20\n",
      " - 19s - loss: 1.0463e-04 - acc: 1.0000 - val_loss: 0.8419 - val_acc: 0.8456\n",
      "Epoch 15/20\n",
      " - 18s - loss: 8.7460e-05 - acc: 1.0000 - val_loss: 0.8581 - val_acc: 0.8448\n",
      "Epoch 16/20\n",
      " - 18s - loss: 7.4471e-05 - acc: 1.0000 - val_loss: 0.8675 - val_acc: 0.8451\n",
      "Epoch 17/20\n",
      " - 19s - loss: 6.3674e-05 - acc: 1.0000 - val_loss: 0.8897 - val_acc: 0.8435\n",
      "Epoch 18/20\n",
      " - 19s - loss: 5.5388e-05 - acc: 1.0000 - val_loss: 0.8952 - val_acc: 0.8445\n",
      "Epoch 19/20\n",
      " - 19s - loss: 4.8420e-05 - acc: 1.0000 - val_loss: 0.9016 - val_acc: 0.8440\n",
      "Epoch 20/20\n",
      " - 19s - loss: 4.2521e-05 - acc: 1.0000 - val_loss: 0.9131 - val_acc: 0.8437\n",
      "5000/5000 [==============================] - 3s 509us/step\n",
      "10000/10000 [==============================] - 5s 501us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 0.3851 - acc: 0.8487 - val_loss: 0.4434 - val_acc: 0.8260\n",
      "Epoch 2/20\n",
      " - 17s - loss: 0.0951 - acc: 0.9735 - val_loss: 0.3537 - val_acc: 0.8726\n",
      "Epoch 3/20\n",
      " - 17s - loss: 0.0248 - acc: 0.9971 - val_loss: 0.4711 - val_acc: 0.8573\n",
      "Epoch 4/20\n",
      " - 17s - loss: 0.0081 - acc: 0.9994 - val_loss: 0.5925 - val_acc: 0.8432\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0036 - acc: 0.9999 - val_loss: 0.5932 - val_acc: 0.8518\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0019 - acc: 0.9999 - val_loss: 0.6263 - val_acc: 0.8534\n",
      "Epoch 7/20\n",
      " - 17s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.8475\n",
      "Epoch 8/20\n",
      " - 18s - loss: 7.0522e-04 - acc: 1.0000 - val_loss: 0.6608 - val_acc: 0.8547\n",
      "Epoch 9/20\n",
      " - 17s - loss: 4.6368e-04 - acc: 1.0000 - val_loss: 0.7003 - val_acc: 0.8522\n",
      "Epoch 10/20\n",
      " - 17s - loss: 3.2572e-04 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.8497\n",
      "Epoch 11/20\n",
      " - 17s - loss: 2.4413e-04 - acc: 1.0000 - val_loss: 0.7061 - val_acc: 0.8562\n",
      "Epoch 12/20\n",
      " - 17s - loss: 1.9126e-04 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.8546\n",
      "Epoch 13/20\n",
      " - 17s - loss: 1.4554e-04 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.8516\n",
      "Epoch 14/20\n",
      " - 17s - loss: 1.2213e-04 - acc: 1.0000 - val_loss: 0.7724 - val_acc: 0.8524\n",
      "Epoch 15/20\n",
      " - 17s - loss: 1.0055e-04 - acc: 1.0000 - val_loss: 0.7919 - val_acc: 0.8510\n",
      "Epoch 16/20\n",
      " - 17s - loss: 8.5254e-05 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.8525\n",
      "Epoch 17/20\n",
      " - 18s - loss: 7.1344e-05 - acc: 1.0000 - val_loss: 0.8094 - val_acc: 0.8510\n",
      "Epoch 18/20\n",
      " - 18s - loss: 5.9260e-05 - acc: 1.0000 - val_loss: 0.8190 - val_acc: 0.8512\n",
      "Epoch 19/20\n",
      " - 17s - loss: 5.4885e-05 - acc: 1.0000 - val_loss: 0.8255 - val_acc: 0.8514\n",
      "Epoch 20/20\n",
      " - 17s - loss: 4.4309e-05 - acc: 1.0000 - val_loss: 0.8316 - val_acc: 0.8520\n",
      "5000/5000 [==============================] - 2s 474us/step\n",
      "10000/10000 [==============================] - 5s 476us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 20s - loss: 0.4067 - acc: 0.8184 - val_loss: 0.2977 - val_acc: 0.8808\n",
      "Epoch 2/20\n",
      " - 19s - loss: 0.0825 - acc: 0.9790 - val_loss: 0.3144 - val_acc: 0.8871\n",
      "Epoch 3/20\n",
      " - 19s - loss: 0.0204 - acc: 0.9978 - val_loss: 0.3968 - val_acc: 0.8795\n",
      "Epoch 4/20\n",
      " - 19s - loss: 0.0066 - acc: 0.9997 - val_loss: 0.4098 - val_acc: 0.8878\n",
      "Epoch 5/20\n",
      " - 19s - loss: 0.0025 - acc: 0.9998 - val_loss: 0.4345 - val_acc: 0.8874\n",
      "Epoch 6/20\n",
      " - 19s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.4576 - val_acc: 0.8864\n",
      "Epoch 7/20\n",
      " - 19s - loss: 7.4846e-04 - acc: 1.0000 - val_loss: 0.4763 - val_acc: 0.8861\n",
      "Epoch 8/20\n",
      " - 19s - loss: 4.8365e-04 - acc: 1.0000 - val_loss: 0.4957 - val_acc: 0.8873\n",
      "Epoch 9/20\n",
      " - 19s - loss: 3.1563e-04 - acc: 1.0000 - val_loss: 0.5119 - val_acc: 0.8866\n",
      "Epoch 10/20\n",
      " - 19s - loss: 2.1738e-04 - acc: 1.0000 - val_loss: 0.5258 - val_acc: 0.8862\n",
      "Epoch 11/20\n",
      " - 19s - loss: 1.6475e-04 - acc: 1.0000 - val_loss: 0.5388 - val_acc: 0.8860\n",
      "Epoch 12/20\n",
      " - 19s - loss: 1.2256e-04 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.8857\n",
      "Epoch 13/20\n",
      " - 19s - loss: 9.8885e-05 - acc: 1.0000 - val_loss: 0.5608 - val_acc: 0.8844\n",
      "Epoch 14/20\n",
      " - 20s - loss: 7.5810e-05 - acc: 1.0000 - val_loss: 0.5709 - val_acc: 0.8843\n",
      "Epoch 15/20\n",
      " - 19s - loss: 6.3618e-05 - acc: 1.0000 - val_loss: 0.5788 - val_acc: 0.8839\n",
      "Epoch 16/20\n",
      " - 19s - loss: 5.0657e-05 - acc: 1.0000 - val_loss: 0.5867 - val_acc: 0.8839\n",
      "Epoch 17/20\n",
      " - 19s - loss: 4.4055e-05 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.8846\n",
      "Epoch 18/20\n",
      " - 19s - loss: 3.6058e-05 - acc: 1.0000 - val_loss: 0.6010 - val_acc: 0.8834\n",
      "Epoch 19/20\n",
      " - 19s - loss: 3.0689e-05 - acc: 1.0000 - val_loss: 0.6075 - val_acc: 0.8831\n",
      "Epoch 20/20\n",
      " - 19s - loss: 2.6596e-05 - acc: 1.0000 - val_loss: 0.6137 - val_acc: 0.8832\n",
      "5000/5000 [==============================] - 3s 523us/step\n",
      "10000/10000 [==============================] - 5s 530us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 0.3753 - acc: 0.8562 - val_loss: 0.3818 - val_acc: 0.8464\n",
      "Epoch 2/20\n",
      " - 17s - loss: 0.0792 - acc: 0.9776 - val_loss: 0.4185 - val_acc: 0.8549\n",
      "Epoch 3/20\n",
      " - 18s - loss: 0.0180 - acc: 0.9984 - val_loss: 0.5198 - val_acc: 0.8474\n",
      "Epoch 4/20\n",
      " - 18s - loss: 0.0054 - acc: 0.9999 - val_loss: 0.5920 - val_acc: 0.8475\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.6210 - val_acc: 0.8489\n",
      "Epoch 6/20\n",
      " - 18s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6761 - val_acc: 0.8451\n",
      "Epoch 7/20\n",
      " - 17s - loss: 8.4184e-04 - acc: 1.0000 - val_loss: 0.7256 - val_acc: 0.8429\n",
      "Epoch 8/20\n",
      " - 18s - loss: 5.6854e-04 - acc: 1.0000 - val_loss: 0.7023 - val_acc: 0.8502\n",
      "Epoch 9/20\n",
      " - 18s - loss: 3.9788e-04 - acc: 1.0000 - val_loss: 0.7419 - val_acc: 0.8469\n",
      "Epoch 10/20\n",
      " - 19s - loss: 2.8733e-04 - acc: 1.0000 - val_loss: 0.7702 - val_acc: 0.8457\n",
      "Epoch 11/20\n",
      " - 18s - loss: 2.1826e-04 - acc: 1.0000 - val_loss: 0.7915 - val_acc: 0.8456\n",
      "Epoch 12/20\n",
      " - 17s - loss: 1.7126e-04 - acc: 1.0000 - val_loss: 0.8129 - val_acc: 0.8447\n",
      "Epoch 13/20\n",
      " - 18s - loss: 1.8325e-04 - acc: 1.0000 - val_loss: 0.8633 - val_acc: 0.8384\n",
      "Epoch 14/20\n",
      " - 18s - loss: 1.3370e-04 - acc: 1.0000 - val_loss: 0.8267 - val_acc: 0.8453\n",
      "Epoch 15/20\n",
      " - 18s - loss: 1.0738e-04 - acc: 1.0000 - val_loss: 0.8189 - val_acc: 0.8470\n",
      "Epoch 16/20\n",
      " - 18s - loss: 8.7678e-05 - acc: 1.0000 - val_loss: 0.8358 - val_acc: 0.8473\n",
      "Epoch 17/20\n",
      " - 20s - loss: 7.3648e-05 - acc: 1.0000 - val_loss: 0.8490 - val_acc: 0.8470\n",
      "Epoch 18/20\n",
      " - 18s - loss: 6.5240e-05 - acc: 1.0000 - val_loss: 0.8416 - val_acc: 0.8494\n",
      "Epoch 19/20\n",
      " - 18s - loss: 5.6512e-05 - acc: 1.0000 - val_loss: 0.8991 - val_acc: 0.8425\n",
      "Epoch 20/20\n",
      " - 18s - loss: 5.0795e-05 - acc: 1.0000 - val_loss: 0.8757 - val_acc: 0.8464\n",
      "5000/5000 [==============================] - 3s 520us/step\n",
      "10000/10000 [==============================] - 5s 504us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 0.4327 - acc: 0.8264 - val_loss: 0.3320 - val_acc: 0.8769\n",
      "Epoch 2/20\n",
      " - 17s - loss: 0.1357 - acc: 0.9604 - val_loss: 0.3811 - val_acc: 0.8580\n",
      "Epoch 3/20\n",
      " - 17s - loss: 0.0436 - acc: 0.9936 - val_loss: 0.3859 - val_acc: 0.8688\n",
      "Epoch 4/20\n",
      " - 17s - loss: 0.0152 - acc: 0.9990 - val_loss: 0.4936 - val_acc: 0.8575\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0063 - acc: 0.9996 - val_loss: 0.5712 - val_acc: 0.8507\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0032 - acc: 0.9998 - val_loss: 0.6294 - val_acc: 0.8454\n",
      "Epoch 7/20\n",
      " - 19s - loss: 0.0026 - acc: 0.9999 - val_loss: 0.6425 - val_acc: 0.8477\n",
      "Epoch 8/20\n",
      " - 17s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6249 - val_acc: 0.8559\n",
      "Epoch 9/20\n",
      " - 17s - loss: 8.8342e-04 - acc: 1.0000 - val_loss: 0.6509 - val_acc: 0.8546\n",
      "Epoch 10/20\n",
      " - 17s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.6498 - val_acc: 0.8518\n",
      "Epoch 11/20\n",
      " - 17s - loss: 0.0026 - acc: 0.9994 - val_loss: 0.6911 - val_acc: 0.8450\n",
      "Epoch 12/20\n",
      " - 17s - loss: 0.0018 - acc: 0.9998 - val_loss: 0.6251 - val_acc: 0.8608\n",
      "Epoch 13/20\n",
      " - 17s - loss: 0.0011 - acc: 0.9999 - val_loss: 0.5971 - val_acc: 0.8670\n",
      "Epoch 14/20\n",
      " - 17s - loss: 0.0012 - acc: 0.9998 - val_loss: 0.6922 - val_acc: 0.8552\n",
      "Epoch 15/20\n",
      " - 17s - loss: 4.5150e-04 - acc: 1.0000 - val_loss: 0.8384 - val_acc: 0.8387\n",
      "Epoch 16/20\n",
      " - 17s - loss: 2.8728e-04 - acc: 1.0000 - val_loss: 0.8276 - val_acc: 0.8418\n",
      "Epoch 17/20\n",
      " - 17s - loss: 2.0121e-04 - acc: 1.0000 - val_loss: 0.8263 - val_acc: 0.8437\n",
      "Epoch 18/20\n",
      " - 17s - loss: 1.6458e-04 - acc: 1.0000 - val_loss: 0.8394 - val_acc: 0.8436\n",
      "Epoch 19/20\n",
      " - 17s - loss: 1.3821e-04 - acc: 1.0000 - val_loss: 0.8426 - val_acc: 0.8442\n",
      "Epoch 20/20\n",
      " - 17s - loss: 1.1840e-04 - acc: 1.0000 - val_loss: 0.8473 - val_acc: 0.8448\n",
      "5000/5000 [==============================] - 3s 556us/step\n",
      "10000/10000 [==============================] - 5s 472us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 0.3713 - acc: 0.8361 - val_loss: 0.3863 - val_acc: 0.8494\n",
      "Epoch 2/20\n",
      " - 17s - loss: 0.0730 - acc: 0.9810 - val_loss: 0.3328 - val_acc: 0.8907\n",
      "Epoch 3/20\n",
      " - 17s - loss: 0.0176 - acc: 0.9980 - val_loss: 0.3816 - val_acc: 0.8868\n",
      "Epoch 4/20\n",
      " - 18s - loss: 0.0057 - acc: 0.9996 - val_loss: 0.4223 - val_acc: 0.8859\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0026 - acc: 0.9998 - val_loss: 0.4388 - val_acc: 0.8865\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.4594 - val_acc: 0.8863\n",
      "Epoch 7/20\n",
      " - 17s - loss: 8.3300e-04 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8859\n",
      "Epoch 8/20\n",
      " - 17s - loss: 5.5214e-04 - acc: 1.0000 - val_loss: 0.4963 - val_acc: 0.8859\n",
      "Epoch 9/20\n",
      " - 17s - loss: 4.0092e-04 - acc: 1.0000 - val_loss: 0.5083 - val_acc: 0.8861\n",
      "Epoch 10/20\n",
      " - 17s - loss: 2.8338e-04 - acc: 1.0000 - val_loss: 0.5218 - val_acc: 0.8859\n",
      "Epoch 11/20\n",
      " - 17s - loss: 2.0734e-04 - acc: 1.0000 - val_loss: 0.5336 - val_acc: 0.8853\n",
      "Epoch 12/20\n",
      " - 17s - loss: 1.6491e-04 - acc: 1.0000 - val_loss: 0.5436 - val_acc: 0.8857\n",
      "Epoch 13/20\n",
      " - 17s - loss: 1.3508e-04 - acc: 1.0000 - val_loss: 0.5533 - val_acc: 0.8857\n",
      "Epoch 14/20\n",
      " - 17s - loss: 9.6834e-05 - acc: 1.0000 - val_loss: 0.5630 - val_acc: 0.8856\n",
      "Epoch 15/20\n",
      " - 17s - loss: 1.0225e-04 - acc: 1.0000 - val_loss: 0.5607 - val_acc: 0.8851\n",
      "Epoch 16/20\n",
      " - 17s - loss: 1.0290e-04 - acc: 1.0000 - val_loss: 0.5598 - val_acc: 0.8849\n",
      "Epoch 17/20\n",
      " - 17s - loss: 6.7565e-05 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.8850\n",
      "Epoch 18/20\n",
      " - 17s - loss: 5.1943e-05 - acc: 1.0000 - val_loss: 0.5860 - val_acc: 0.8839\n",
      "Epoch 19/20\n",
      " - 17s - loss: 4.6141e-05 - acc: 1.0000 - val_loss: 0.5924 - val_acc: 0.8838\n",
      "Epoch 20/20\n",
      " - 17s - loss: 3.9692e-05 - acc: 1.0000 - val_loss: 0.5984 - val_acc: 0.8843\n",
      "5000/5000 [==============================] - 3s 562us/step\n",
      "10000/10000 [==============================] - 5s 461us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 0.4007 - acc: 0.8509 - val_loss: 0.3523 - val_acc: 0.8582\n",
      "Epoch 2/20\n",
      " - 18s - loss: 0.1083 - acc: 0.9663 - val_loss: 0.3902 - val_acc: 0.8582\n",
      "Epoch 3/20\n",
      " - 17s - loss: 0.0322 - acc: 0.9958 - val_loss: 0.3935 - val_acc: 0.8693\n",
      "Epoch 4/20\n",
      " - 17s - loss: 0.0109 - acc: 0.9992 - val_loss: 0.5655 - val_acc: 0.8424\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0048 - acc: 0.9999 - val_loss: 0.6059 - val_acc: 0.8438\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0025 - acc: 0.9999 - val_loss: 0.6658 - val_acc: 0.8411\n",
      "Epoch 7/20\n",
      " - 17s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.6813 - val_acc: 0.8437\n",
      "Epoch 8/20\n",
      " - 17s - loss: 9.5070e-04 - acc: 1.0000 - val_loss: 0.6425 - val_acc: 0.8548\n",
      "Epoch 9/20\n",
      " - 17s - loss: 7.7194e-04 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.8360\n",
      "Epoch 10/20\n",
      " - 17s - loss: 5.6111e-04 - acc: 1.0000 - val_loss: 0.7742 - val_acc: 0.8399\n",
      "Epoch 11/20\n",
      " - 17s - loss: 4.2223e-04 - acc: 1.0000 - val_loss: 0.6955 - val_acc: 0.8558\n",
      "Epoch 12/20\n",
      " - 17s - loss: 3.0815e-04 - acc: 1.0000 - val_loss: 0.7539 - val_acc: 0.8491\n",
      "Epoch 13/20\n",
      " - 17s - loss: 4.4080e-04 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.8658\n",
      "Epoch 14/20\n",
      " - 17s - loss: 0.0021 - acc: 0.9998 - val_loss: 0.8863 - val_acc: 0.8291\n",
      "Epoch 15/20\n",
      " - 17s - loss: 5.0348e-04 - acc: 1.0000 - val_loss: 0.8043 - val_acc: 0.8451\n",
      "Epoch 16/20\n",
      " - 17s - loss: 2.5759e-04 - acc: 1.0000 - val_loss: 0.8039 - val_acc: 0.8500\n",
      "Epoch 17/20\n",
      " - 17s - loss: 1.9924e-04 - acc: 1.0000 - val_loss: 0.9453 - val_acc: 0.8326\n",
      "Epoch 18/20\n",
      " - 17s - loss: 1.4332e-04 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 0.8443\n",
      "Epoch 19/20\n",
      " - 17s - loss: 1.1545e-04 - acc: 1.0000 - val_loss: 0.8685 - val_acc: 0.8481\n",
      "Epoch 20/20\n",
      " - 17s - loss: 1.0192e-04 - acc: 1.0000 - val_loss: 0.8820 - val_acc: 0.8465\n",
      "5000/5000 [==============================] - 3s 523us/step\n",
      "10000/10000 [==============================] - 5s 512us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 0.4041 - acc: 0.8388 - val_loss: 0.3511 - val_acc: 0.8652\n",
      "Epoch 2/20\n",
      " - 16s - loss: 0.1196 - acc: 0.9638 - val_loss: 0.4928 - val_acc: 0.8250\n",
      "Epoch 3/20\n",
      " - 16s - loss: 0.0386 - acc: 0.9945 - val_loss: 0.4724 - val_acc: 0.8496\n",
      "Epoch 4/20\n",
      " - 17s - loss: 0.0148 - acc: 0.9989 - val_loss: 0.5784 - val_acc: 0.8410\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0068 - acc: 0.9996 - val_loss: 0.5578 - val_acc: 0.8545\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0035 - acc: 0.9998 - val_loss: 0.6361 - val_acc: 0.8462\n",
      "Epoch 7/20\n",
      " - 17s - loss: 0.0023 - acc: 0.9999 - val_loss: 0.6890 - val_acc: 0.8428\n",
      "Epoch 8/20\n",
      " - 17s - loss: 0.0029 - acc: 0.9996 - val_loss: 0.7848 - val_acc: 0.8275\n",
      "Epoch 9/20\n",
      " - 17s - loss: 0.0042 - acc: 0.9995 - val_loss: 0.6250 - val_acc: 0.8553\n",
      "Epoch 10/20\n",
      " - 17s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6592 - val_acc: 0.8567\n",
      "Epoch 11/20\n",
      " - 17s - loss: 0.0025 - acc: 0.9996 - val_loss: 0.7587 - val_acc: 0.8426\n",
      "Epoch 12/20\n",
      " - 17s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.6994 - val_acc: 0.8534\n",
      "Epoch 13/20\n",
      " - 17s - loss: 6.0506e-04 - acc: 1.0000 - val_loss: 0.7840 - val_acc: 0.8443\n",
      "Epoch 14/20\n",
      " - 17s - loss: 4.0751e-04 - acc: 1.0000 - val_loss: 0.7888 - val_acc: 0.8461\n",
      "Epoch 15/20\n",
      " - 16s - loss: 2.6514e-04 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.8462\n",
      "Epoch 16/20\n",
      " - 16s - loss: 2.7198e-04 - acc: 1.0000 - val_loss: 0.8320 - val_acc: 0.8439\n",
      "Epoch 17/20\n",
      " - 17s - loss: 2.2827e-04 - acc: 1.0000 - val_loss: 0.7906 - val_acc: 0.8519\n",
      "Epoch 18/20\n",
      " - 17s - loss: 1.7292e-04 - acc: 1.0000 - val_loss: 0.8125 - val_acc: 0.8510\n",
      "Epoch 19/20\n",
      " - 17s - loss: 1.4334e-04 - acc: 1.0000 - val_loss: 0.8656 - val_acc: 0.8452\n",
      "Epoch 20/20\n",
      " - 16s - loss: 1.2632e-04 - acc: 1.0000 - val_loss: 0.8348 - val_acc: 0.8507\n",
      "5000/5000 [==============================] - 2s 488us/step\n",
      "10000/10000 [==============================] - 5s 478us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 0.3856 - acc: 0.8354 - val_loss: 0.2943 - val_acc: 0.8861\n",
      "Epoch 2/20\n",
      " - 16s - loss: 0.0852 - acc: 0.9785 - val_loss: 0.3211 - val_acc: 0.8888\n",
      "Epoch 3/20\n",
      " - 16s - loss: 0.0239 - acc: 0.9974 - val_loss: 0.3588 - val_acc: 0.8886\n",
      "Epoch 4/20\n",
      " - 16s - loss: 0.0078 - acc: 0.9995 - val_loss: 0.4009 - val_acc: 0.8890\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0054 - acc: 0.9993 - val_loss: 0.4564 - val_acc: 0.8767\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0031 - acc: 0.9997 - val_loss: 0.4523 - val_acc: 0.8871\n",
      "Epoch 7/20\n",
      " - 17s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.4773 - val_acc: 0.8834\n",
      "Epoch 8/20\n",
      " - 17s - loss: 0.0015 - acc: 0.9999 - val_loss: 0.4843 - val_acc: 0.8877\n",
      "Epoch 9/20\n",
      " - 17s - loss: 0.0011 - acc: 0.9999 - val_loss: 0.5022 - val_acc: 0.8871\n",
      "Epoch 10/20\n",
      " - 16s - loss: 5.6131e-04 - acc: 0.9999 - val_loss: 0.5153 - val_acc: 0.8865\n",
      "Epoch 11/20\n",
      " - 17s - loss: 3.5006e-04 - acc: 1.0000 - val_loss: 0.5249 - val_acc: 0.8849\n",
      "Epoch 12/20\n",
      " - 17s - loss: 2.8704e-04 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.8851\n",
      "Epoch 13/20\n",
      " - 17s - loss: 2.2054e-04 - acc: 1.0000 - val_loss: 0.5427 - val_acc: 0.8841\n",
      "Epoch 14/20\n",
      " - 17s - loss: 1.7818e-04 - acc: 1.0000 - val_loss: 0.5502 - val_acc: 0.8863\n",
      "Epoch 15/20\n",
      " - 17s - loss: 1.5131e-04 - acc: 1.0000 - val_loss: 0.5558 - val_acc: 0.8853\n",
      "Epoch 16/20\n",
      " - 17s - loss: 1.2239e-04 - acc: 1.0000 - val_loss: 0.5612 - val_acc: 0.8837\n",
      "Epoch 17/20\n",
      " - 17s - loss: 1.0712e-04 - acc: 1.0000 - val_loss: 0.5684 - val_acc: 0.8863\n",
      "Epoch 18/20\n",
      " - 17s - loss: 1.0182e-04 - acc: 1.0000 - val_loss: 0.5732 - val_acc: 0.8847\n",
      "Epoch 19/20\n",
      " - 17s - loss: 9.0887e-05 - acc: 1.0000 - val_loss: 0.5767 - val_acc: 0.8858\n",
      "Epoch 20/20\n",
      " - 17s - loss: 7.5976e-05 - acc: 1.0000 - val_loss: 0.5841 - val_acc: 0.8844\n",
      "5000/5000 [==============================] - 2s 473us/step\n",
      "10000/10000 [==============================] - 5s 460us/step\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 19s - loss: 0.3607 - acc: 0.8600 - val_loss: 0.4031 - val_acc: 0.8397\n",
      "Epoch 2/20\n",
      " - 17s - loss: 0.0856 - acc: 0.9757 - val_loss: 0.4213 - val_acc: 0.8535\n",
      "Epoch 3/20\n",
      " - 17s - loss: 0.0236 - acc: 0.9974 - val_loss: 0.4831 - val_acc: 0.8528\n",
      "Epoch 4/20\n",
      " - 17s - loss: 0.0078 - acc: 0.9997 - val_loss: 0.5461 - val_acc: 0.8547\n",
      "Epoch 5/20\n",
      " - 17s - loss: 0.0038 - acc: 0.9999 - val_loss: 0.5889 - val_acc: 0.8548\n",
      "Epoch 6/20\n",
      " - 17s - loss: 0.0022 - acc: 0.9998 - val_loss: 0.6342 - val_acc: 0.8504\n",
      "Epoch 7/20\n",
      " - 17s - loss: 0.0014 - acc: 0.9999 - val_loss: 0.6158 - val_acc: 0.8570\n",
      "Epoch 8/20\n",
      " - 17s - loss: 0.0012 - acc: 0.9998 - val_loss: 0.6162 - val_acc: 0.8601\n",
      "Epoch 9/20\n",
      " - 17s - loss: 8.0014e-04 - acc: 1.0000 - val_loss: 0.7535 - val_acc: 0.8451\n",
      "Epoch 10/20\n",
      " - 17s - loss: 5.0654e-04 - acc: 1.0000 - val_loss: 0.7505 - val_acc: 0.8479\n",
      "Epoch 11/20\n",
      " - 17s - loss: 3.8330e-04 - acc: 1.0000 - val_loss: 0.7856 - val_acc: 0.8454\n",
      "Epoch 12/20\n",
      " - 18s - loss: 2.9507e-04 - acc: 1.0000 - val_loss: 0.7527 - val_acc: 0.8509\n",
      "Epoch 13/20\n",
      " - 17s - loss: 2.2994e-04 - acc: 1.0000 - val_loss: 0.7997 - val_acc: 0.8478\n",
      "Epoch 14/20\n",
      " - 18s - loss: 2.0355e-04 - acc: 1.0000 - val_loss: 0.7877 - val_acc: 0.8505\n",
      "Epoch 15/20\n",
      " - 17s - loss: 1.6609e-04 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.8528\n",
      "Epoch 16/20\n",
      " - 18s - loss: 1.3876e-04 - acc: 1.0000 - val_loss: 0.8346 - val_acc: 0.8474\n",
      "Epoch 17/20\n",
      " - 17s - loss: 1.1573e-04 - acc: 1.0000 - val_loss: 0.8373 - val_acc: 0.8479\n",
      "Epoch 18/20\n",
      " - 17s - loss: 1.1519e-04 - acc: 1.0000 - val_loss: 0.8507 - val_acc: 0.8476\n",
      "Epoch 19/20\n",
      " - 17s - loss: 9.4418e-05 - acc: 1.0000 - val_loss: 0.8600 - val_acc: 0.8477\n",
      "Epoch 20/20\n",
      " - 17s - loss: 7.8972e-05 - acc: 1.0000 - val_loss: 0.8455 - val_acc: 0.8507\n",
      "5000/5000 [==============================] - 3s 510us/step\n",
      "10000/10000 [==============================] - 5s 501us/step\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 25s - loss: 0.3442 - acc: 0.8504 - val_loss: 0.2811 - val_acc: 0.8908\n",
      "Epoch 2/20\n",
      " - 24s - loss: 0.0845 - acc: 0.9761 - val_loss: 0.3251 - val_acc: 0.8882\n",
      "Epoch 3/20\n",
      " - 23s - loss: 0.0284 - acc: 0.9949 - val_loss: 0.3912 - val_acc: 0.8912\n",
      "Epoch 4/20\n",
      " - 24s - loss: 0.0092 - acc: 0.9992 - val_loss: 0.4394 - val_acc: 0.8883\n",
      "Epoch 5/20\n",
      " - 23s - loss: 0.0036 - acc: 0.9997 - val_loss: 0.4743 - val_acc: 0.8886\n",
      "Epoch 6/20\n",
      " - 25s - loss: 0.0017 - acc: 0.9999 - val_loss: 0.4963 - val_acc: 0.8891\n",
      "Epoch 7/20\n",
      " - 24s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5189 - val_acc: 0.8894\n",
      "Epoch 8/20\n",
      " - 25s - loss: 6.6928e-04 - acc: 1.0000 - val_loss: 0.5324 - val_acc: 0.8899\n",
      "Epoch 9/20\n",
      " - 23s - loss: 5.0656e-04 - acc: 1.0000 - val_loss: 0.5471 - val_acc: 0.8871\n",
      "Epoch 10/20\n",
      " - 24s - loss: 0.0032 - acc: 0.9994 - val_loss: 0.5524 - val_acc: 0.8868\n",
      "Epoch 11/20\n",
      " - 23s - loss: 0.0043 - acc: 0.9991 - val_loss: 0.6164 - val_acc: 0.8801\n",
      "Epoch 12/20\n",
      " - 25s - loss: 0.0065 - acc: 0.9979 - val_loss: 0.6193 - val_acc: 0.8801\n",
      "Epoch 13/20\n",
      " - 23s - loss: 0.0312 - acc: 0.9919 - val_loss: 0.7555 - val_acc: 0.8677\n",
      "Epoch 14/20\n",
      " - 25s - loss: 0.0357 - acc: 0.9896 - val_loss: 0.6933 - val_acc: 0.8664\n",
      "Epoch 15/20\n",
      " - 24s - loss: 0.0215 - acc: 0.9937 - val_loss: 0.8886 - val_acc: 0.8569\n",
      "Epoch 16/20\n",
      " - 25s - loss: 0.0153 - acc: 0.9958 - val_loss: 0.7470 - val_acc: 0.8763\n",
      "Epoch 17/20\n",
      " - 23s - loss: 0.0032 - acc: 0.9993 - val_loss: 0.7918 - val_acc: 0.8727\n",
      "Epoch 18/20\n",
      " - 25s - loss: 0.0035 - acc: 0.9993 - val_loss: 0.7854 - val_acc: 0.8782\n",
      "Epoch 19/20\n",
      " - 23s - loss: 6.9118e-04 - acc: 0.9999 - val_loss: 0.7985 - val_acc: 0.8796\n",
      "Epoch 20/20\n",
      " - 25s - loss: 2.6871e-04 - acc: 1.0000 - val_loss: 0.8031 - val_acc: 0.8799\n",
      "Best: 0.799333 using {'batch_size': 200, 'epochs': 10, 'dropout_rate': 0.3}\n",
      "Execution time: 4782.695160150528 ms\n"
     ]
    }
   ],
   "source": [
    "# ALLGRAM W/ SW:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import expon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# below, dictionary of params being modified\n",
    "dropout_range = [0, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(dropout_rate=dropout_range, epochs=[10], batch_size=[200]) \n",
    "\n",
    "# random search\n",
    "model = KerasClassifier(build_fn=baseline_model) \n",
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=3, n_iter=4)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_dropout = random_result.best_params_['dropout_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 35s - loss: 0.3579 - acc: 0.8472 - val_loss: 0.2794 - val_acc: 0.8928\n",
      "Epoch 2/20\n",
      " - 25s - loss: 0.0901 - acc: 0.9747 - val_loss: 0.3195 - val_acc: 0.8899\n",
      "Epoch 3/20\n",
      " - 26s - loss: 0.0280 - acc: 0.9950 - val_loss: 0.3974 - val_acc: 0.8809\n",
      "Epoch 4/20\n",
      " - 26s - loss: 0.0101 - acc: 0.9988 - val_loss: 0.4223 - val_acc: 0.8901\n",
      "Epoch 5/20\n",
      " - 27s - loss: 0.0041 - acc: 0.9997 - val_loss: 0.4579 - val_acc: 0.8907\n",
      "Epoch 6/20\n",
      " - 25s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4806 - val_acc: 0.8901\n",
      "Epoch 7/20\n",
      " - 26s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5013 - val_acc: 0.8904\n",
      "Epoch 8/20\n",
      " - 26s - loss: 6.7226e-04 - acc: 1.0000 - val_loss: 0.5146 - val_acc: 0.8897\n",
      "Epoch 9/20\n",
      " - 27s - loss: 4.5617e-04 - acc: 1.0000 - val_loss: 0.5313 - val_acc: 0.8897\n",
      "Epoch 10/20\n",
      " - 25s - loss: 3.5621e-04 - acc: 1.0000 - val_loss: 0.5429 - val_acc: 0.8907\n",
      "Epoch 11/20\n",
      " - 26s - loss: 2.6735e-04 - acc: 1.0000 - val_loss: 0.5532 - val_acc: 0.8896\n",
      "Epoch 12/20\n",
      " - 26s - loss: 1.9683e-04 - acc: 1.0000 - val_loss: 0.5630 - val_acc: 0.8895\n",
      "Epoch 13/20\n",
      " - 26s - loss: 1.5727e-04 - acc: 1.0000 - val_loss: 0.5732 - val_acc: 0.8900\n",
      "Epoch 14/20\n",
      " - 26s - loss: 1.3533e-04 - acc: 1.0000 - val_loss: 0.5837 - val_acc: 0.8895\n",
      "Epoch 15/20\n",
      " - 26s - loss: 1.0964e-04 - acc: 1.0000 - val_loss: 0.5898 - val_acc: 0.8896\n",
      "Epoch 16/20\n",
      " - 26s - loss: 8.7034e-05 - acc: 1.0000 - val_loss: 0.5987 - val_acc: 0.8893\n",
      "Epoch 17/20\n",
      " - 27s - loss: 7.5163e-05 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.8892\n",
      "Epoch 18/20\n",
      " - 26s - loss: 6.9718e-05 - acc: 1.0000 - val_loss: 0.6200 - val_acc: 0.8877\n",
      "Epoch 19/20\n",
      " - 26s - loss: 6.4883e-05 - acc: 1.0000 - val_loss: 0.6102 - val_acc: 0.8892\n",
      "Epoch 20/20\n",
      " - 27s - loss: 5.2918e-05 - acc: 1.0000 - val_loss: 0.6224 - val_acc: 0.8884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1dd29f0470>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train allgram model (uni, bi, tri) w/o stop words w/ best dropout\n",
    "allgram_model = baseline_model(best_dropout)\n",
    "allgram_model.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = allgram_model.evaluate(test_allgram_w_sw, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.7464952216601372\n",
      "Test accuracy:  0.87388\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Attempted Architecture: L2 Regularization for overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used L2 b/c suggested that this was best regularizer for MLP\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def baseline_model(l2_reg=1e-03):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_shape=(30000,), activation='relu', kernel_regularizer=l2(l2_reg)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 13s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "5000/5000 [==============================] - 6s 1ms/step\n",
      "10000/10000 [==============================] - 12s 1ms/step\n",
      "Best: 0.781400 using {'l2_reg': 1e-05}\n",
      "Execution time: 4916.787871599197 ms\n"
     ]
    }
   ],
   "source": [
    "# ALLGRAM W/O SW:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import expon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# below, dictionary of params being modified\n",
    "l2_range = [1e-1, 1e-3, 1e-5]\n",
    "param_grid = dict(l2_reg=l2_range) \n",
    "\n",
    "# random search\n",
    "model = KerasClassifier(build_fn=baseline_model) \n",
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=3, n_iter=3)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=0)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_allgram, IMDB_train_y = unison_shuffled_copies(train_allgram, IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_allgram = np.asarray(train_allgram)\n",
    "IMDB_train_y = np.asarray(IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_l2 = random_result.best_params_['l2_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 34s - loss: 0.3686 - acc: 0.8534 - val_loss: 0.3168 - val_acc: 0.8866\n",
      "Epoch 2/20\n",
      " - 28s - loss: 0.0951 - acc: 0.9783 - val_loss: 0.3641 - val_acc: 0.8852\n",
      "Epoch 3/20\n",
      " - 29s - loss: 0.0395 - acc: 0.9979 - val_loss: 0.4300 - val_acc: 0.8849\n",
      "Epoch 4/20\n",
      " - 29s - loss: 0.0255 - acc: 0.9999 - val_loss: 0.4665 - val_acc: 0.8848\n",
      "Epoch 5/20\n",
      " - 29s - loss: 0.0208 - acc: 0.9999 - val_loss: 0.4886 - val_acc: 0.8836\n",
      "Epoch 6/20\n",
      " - 29s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.5054 - val_acc: 0.8825\n",
      "Epoch 7/20\n",
      " - 29s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.5165 - val_acc: 0.8819\n",
      "Epoch 8/20\n",
      " - 29s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.5248 - val_acc: 0.8813\n",
      "Epoch 9/20\n",
      " - 29s - loss: 0.0130 - acc: 1.0000 - val_loss: 0.5317 - val_acc: 0.8807\n",
      "Epoch 10/20\n",
      " - 29s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.5416 - val_acc: 0.8802\n",
      "Epoch 11/20\n",
      " - 29s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5527 - val_acc: 0.8799\n",
      "Epoch 12/20\n",
      " - 29s - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5514 - val_acc: 0.8789\n",
      "Epoch 13/20\n",
      " - 29s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5623 - val_acc: 0.8783\n",
      "Epoch 14/20\n",
      " - 29s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.5638 - val_acc: 0.8794\n",
      "Epoch 15/20\n",
      " - 29s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5756 - val_acc: 0.8790\n",
      "Epoch 16/20\n",
      " - 29s - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5826 - val_acc: 0.8780\n",
      "Epoch 17/20\n",
      " - 29s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5865 - val_acc: 0.8782\n",
      "Epoch 18/20\n",
      " - 30s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.6005 - val_acc: 0.8770\n",
      "Epoch 19/20\n",
      " - 29s - loss: 0.0079 - acc: 0.9998 - val_loss: 0.6162 - val_acc: 0.8687\n",
      "Epoch 20/20\n",
      " - 29s - loss: 0.1726 - acc: 0.9454 - val_loss: 0.4924 - val_acc: 0.8665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c50505630>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allgram_model = baseline_model(best_l2)\n",
    "# train trigram model (uni, bi, tri) w/o stop words w/ best l2\n",
    "allgram_model.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy']\n"
     ]
    }
   ],
   "source": [
    "print(allgram_model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = allgram_model.evaluate(test_allgram, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.52534321767807\n",
      "Test accuracy:  0.85004\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "5000/5000 [==============================] - 5s 964us/step\n",
      "10000/10000 [==============================] - 10s 967us/step\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "5000/5000 [==============================] - 5s 966us/step\n",
      "10000/10000 [==============================] - 10s 967us/step\n",
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "5000/5000 [==============================] - 5s 992us/step\n",
      "10000/10000 [==============================] - 10s 979us/step\n",
      "Best: 0.777467 using {'l2_reg': 1e-05}\n",
      "Execution time: 4223.002087831497 ms\n"
     ]
    }
   ],
   "source": [
    "# ALLGRAM W/ SW:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import expon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# below, dictionary of params being modified\n",
    "l2_range = [1e-1, 1e-3, 1e-5]\n",
    "param_grid = dict(l2_reg=l2_range) \n",
    "\n",
    "# random search\n",
    "model = KerasClassifier(build_fn=baseline_model) \n",
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=3, n_iter=3)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=0)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_allgram_w_sw, IMDB_train_y = unison_shuffled_copies(train_allgram_w_sw, IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_allgram_w_sw = np.asarray(train_allgram_w_sw)\n",
    "IMDB_train_y = np.asarray(IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05\n"
     ]
    }
   ],
   "source": [
    "best_l2 = random_result.best_params_['l2_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 45s - loss: 0.3561 - acc: 0.8507 - val_loss: 0.3015 - val_acc: 0.8876\n",
      "Epoch 2/20\n",
      " - 27s - loss: 0.0906 - acc: 0.9796 - val_loss: 0.3460 - val_acc: 0.8867\n",
      "Epoch 3/20\n",
      " - 27s - loss: 0.0386 - acc: 0.9980 - val_loss: 0.3956 - val_acc: 0.8900\n",
      "Epoch 4/20\n",
      " - 26s - loss: 0.0248 - acc: 0.9999 - val_loss: 0.4398 - val_acc: 0.8910\n",
      "Epoch 5/20\n",
      " - 26s - loss: 0.0205 - acc: 1.0000 - val_loss: 0.4586 - val_acc: 0.8908\n",
      "Epoch 6/20\n",
      " - 27s - loss: 0.0180 - acc: 1.0000 - val_loss: 0.4663 - val_acc: 0.8905\n",
      "Epoch 7/20\n",
      " - 27s - loss: 0.0161 - acc: 1.0000 - val_loss: 0.4715 - val_acc: 0.8899\n",
      "Epoch 8/20\n",
      " - 26s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.4725 - val_acc: 0.8893\n",
      "Epoch 9/20\n",
      " - 32s - loss: 0.0130 - acc: 1.0000 - val_loss: 0.4743 - val_acc: 0.8894\n",
      "Epoch 10/20\n",
      " - 27s - loss: 0.0118 - acc: 1.0000 - val_loss: 0.4779 - val_acc: 0.8889\n",
      "Epoch 11/20\n",
      " - 27s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.4815 - val_acc: 0.8870\n",
      "Epoch 12/20\n",
      " - 27s - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4805 - val_acc: 0.8871\n",
      "Epoch 13/20\n",
      " - 27s - loss: 0.0090 - acc: 1.0000 - val_loss: 0.4808 - val_acc: 0.8871\n",
      "Epoch 14/20\n",
      " - 26s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.4918 - val_acc: 0.8859\n",
      "Epoch 15/20\n",
      " - 27s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.4809 - val_acc: 0.8865\n",
      "Epoch 16/20\n",
      " - 27s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.4995 - val_acc: 0.8860\n",
      "Epoch 17/20\n",
      " - 26s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.4901 - val_acc: 0.8856\n",
      "Epoch 18/20\n",
      " - 27s - loss: 0.0084 - acc: 0.9999 - val_loss: 0.5138 - val_acc: 0.8740\n",
      "Epoch 19/20\n",
      " - 27s - loss: 0.1777 - acc: 0.9478 - val_loss: 0.4474 - val_acc: 0.8636\n",
      "Epoch 20/20\n",
      " - 26s - loss: 0.0942 - acc: 0.9886 - val_loss: 0.5219 - val_acc: 0.8747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfd9ebecc0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allgram_w_sw_model = baseline_model(best_l2)\n",
    "# train trigram model (uni, bi, tri) w/ stop words w/ best l2\n",
    "allgram_w_sw_model.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Attempt: Adding early stop from best of (L2 Reg and Dropout) to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 18s - loss: 0.4148 - acc: 0.8353 - val_loss: 0.2999 - val_acc: 0.8870\n",
      "Epoch 2/20\n",
      " - 15s - loss: 0.1672 - acc: 0.9505 - val_loss: 0.2865 - val_acc: 0.8914\n",
      "Epoch 3/20\n",
      " - 15s - loss: 0.0862 - acc: 0.9809 - val_loss: 0.3066 - val_acc: 0.8890\n",
      "Epoch 4/20\n",
      " - 15s - loss: 0.0483 - acc: 0.9935 - val_loss: 0.3288 - val_acc: 0.8885\n",
      "Epoch 5/20\n",
      " - 15s - loss: 0.0279 - acc: 0.9979 - val_loss: 0.3556 - val_acc: 0.8877\n",
      "Epoch 6/20\n",
      " - 15s - loss: 0.0179 - acc: 0.9991 - val_loss: 0.3811 - val_acc: 0.8860\n",
      "Epoch 7/20\n",
      " - 15s - loss: 0.0121 - acc: 0.9995 - val_loss: 0.3998 - val_acc: 0.8848\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c666ea940>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DROPOUT MODEL PERFORMED BETTER -> USING THAT (w/o sw)\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# create early-stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=2, \n",
    "                          mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "# train trigram model (uni, bi, tri) w/o stop words w/ best dropout\n",
    "allgram_model = baseline_model(best_dropout)\n",
    "allgram_model.fit(train_allgram[:15000], IMDB_train_y[:15000], validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), \n",
    "                  batch_size=200, epochs=20, verbose=2, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = allgram_model.evaluate(test_allgram, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.308475244140625\n",
      "Test accuracy:  0.87748\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 29s - loss: 0.3486 - acc: 0.8556 - val_loss: 0.2761 - val_acc: 0.8950\n",
      "Epoch 2/20\n",
      " - 26s - loss: 0.0820 - acc: 0.9751 - val_loss: 0.3200 - val_acc: 0.8917\n",
      "Epoch 3/20\n",
      " - 26s - loss: 0.0222 - acc: 0.9969 - val_loss: 0.3776 - val_acc: 0.8883\n",
      "Epoch 4/20\n",
      " - 27s - loss: 0.0073 - acc: 0.9996 - val_loss: 0.4308 - val_acc: 0.8876\n",
      "Epoch 5/20\n",
      " - 26s - loss: 0.0033 - acc: 0.9998 - val_loss: 0.4490 - val_acc: 0.8905\n",
      "Epoch 6/20\n",
      " - 26s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4817 - val_acc: 0.8908\n",
      "Epoch 7/20\n",
      " - 27s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5016 - val_acc: 0.8910\n",
      "Epoch 8/20\n",
      " - 27s - loss: 6.4982e-04 - acc: 1.0000 - val_loss: 0.5201 - val_acc: 0.8913\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a248d6160>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DROPOUT MODEL PERFORMED BETTER -> USING THAT (MAKE SURE NOT TO USE L2 MODEL)\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# create early-stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=7, verbose=2, \n",
    "                          mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "# train trigram model (uni, bi, tri) w/ stop words w/ best dropout\n",
    "allgram_w_sw_model = baseline_model(best_dropout)\n",
    "allgram_w_sw_model.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "                       validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), \n",
    "                  batch_size=200, epochs=20, verbose=2, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = allgram_w_sw_model.evaluate(test_allgram_w_sw, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.2778815042543411\n",
      "Test accuracy:  0.88912\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Attempt: Change Optimizer & Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def baseline_model(learn_rate=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_shape=(30000,), activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(lr=learn_rate)\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'baseline_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-58a014656985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# random search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'baseline_model' is not defined"
     ]
    }
   ],
   "source": [
    "# ALLGRAM:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import expon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# below, dictionary of params being modified\n",
    "lr_range = [1e-4, 1e-2, 1e-1, 1]\n",
    "param_grid = dict(learn_rate=lr_range) \n",
    "\n",
    "# random search\n",
    "model = KerasClassifier(build_fn=baseline_model) \n",
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=3, n_iter=3)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=10, verbose=0)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_allgram, IMDB_train_y = unison_shuffled_copies(train_allgram, IMDB_train_y)\n",
    "train_allgram = np.asarray(train_allgram)\n",
    "IMDB_train_y = np.asarray(IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      " - 26s - loss: 0.5627 - acc: 0.7778 - val_loss: 0.4414 - val_acc: 0.8566\n",
      "Epoch 2/30\n",
      " - 26s - loss: 0.3349 - acc: 0.9049 - val_loss: 0.3328 - val_acc: 0.8859\n",
      "Epoch 3/30\n",
      " - 26s - loss: 0.2301 - acc: 0.9397 - val_loss: 0.2953 - val_acc: 0.8922\n",
      "Epoch 4/30\n",
      " - 24s - loss: 0.1701 - acc: 0.9612 - val_loss: 0.2804 - val_acc: 0.8957\n",
      "Epoch 5/30\n",
      " - 25s - loss: 0.1294 - acc: 0.9745 - val_loss: 0.2739 - val_acc: 0.8962\n",
      "Epoch 6/30\n",
      " - 26s - loss: 0.1016 - acc: 0.9829 - val_loss: 0.2750 - val_acc: 0.8958\n",
      "Epoch 7/30\n",
      " - 26s - loss: 0.0798 - acc: 0.9888 - val_loss: 0.2771 - val_acc: 0.8954\n",
      "Epoch 8/30\n",
      " - 26s - loss: 0.0638 - acc: 0.9933 - val_loss: 0.2813 - val_acc: 0.8962\n",
      "Epoch 9/30\n",
      " - 24s - loss: 0.0514 - acc: 0.9950 - val_loss: 0.2878 - val_acc: 0.8959\n",
      "Epoch 10/30\n",
      " - 24s - loss: 0.0420 - acc: 0.9971 - val_loss: 0.2942 - val_acc: 0.8954\n",
      "Epoch 11/30\n",
      " - 24s - loss: 0.0340 - acc: 0.9983 - val_loss: 0.3009 - val_acc: 0.8953\n",
      "Epoch 12/30\n",
      " - 24s - loss: 0.0287 - acc: 0.9986 - val_loss: 0.3095 - val_acc: 0.8941\n",
      "Epoch 13/30\n",
      " - 24s - loss: 0.0241 - acc: 0.9992 - val_loss: 0.3160 - val_acc: 0.8933\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe63707e7f0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with best learning rate\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# create early-stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=2, \n",
    "                          mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "best_lr = random_result.best_params_['learn_rate']\n",
    "allgram_model = baseline_model(best_lr)\n",
    "allgram_model.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=30, verbose=2, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.1457 - acc: 0.9550\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadhvi_mehta/anaconda3/lib/python3.5/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.0815 - acc: 0.9807\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.0560 - acc: 0.9905\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 34s 1ms/step - loss: 0.0412 - acc: 0.9948\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.0316 - acc: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe62c844710>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train over both validation and train\n",
    "\n",
    "allgram_model.fit(train_allgram, IMDB_train_y, \n",
    "          validation_data=None, batch_size=200, epochs=5, verbose=1, callbacks=[earlystop], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allgram_model.save('adam_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = allgram_model.evaluate(test_allgram, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.3021923314857483\n",
      "Test accuracy:  0.88028\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def baseline_model(learn_rate=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_shape=(30000,), activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 4s 800us/step\n",
      "10000/10000 [==============================] - 8s 753us/step\n",
      "5000/5000 [==============================] - 4s 760us/step\n",
      "10000/10000 [==============================] - 7s 739us/step\n",
      "5000/5000 [==============================] - 4s 704us/step\n",
      "10000/10000 [==============================] - 7s 691us/step\n",
      "5000/5000 [==============================] - 4s 753us/step\n",
      "10000/10000 [==============================] - 7s 734us/step\n",
      "5000/5000 [==============================] - 4s 715us/step\n",
      "10000/10000 [==============================] - 7s 703us/step\n",
      "5000/5000 [==============================] - 4s 756us/step\n",
      "10000/10000 [==============================] - 7s 742us/step\n",
      "5000/5000 [==============================] - 4s 754us/step\n",
      "10000/10000 [==============================] - 7s 709us/step\n",
      "5000/5000 [==============================] - 4s 765us/step\n",
      "10000/10000 [==============================] - 7s 742us/step\n",
      "5000/5000 [==============================] - 4s 761us/step\n",
      "10000/10000 [==============================] - 8s 760us/step\n",
      "Best: 0.777733 using {'learn_rate': 0.0001}\n",
      "Execution time: 1928.99249625206 ms\n"
     ]
    }
   ],
   "source": [
    "# ALLGRAM:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import time\n",
    "from scipy.stats import expon\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "# below, dictionary of params being modified\n",
    "lr_range = [1e-4, 1e-2, 1e-1, 1]\n",
    "param_grid = dict(learn_rate=lr_range) \n",
    "\n",
    "# random search\n",
    "model = KerasClassifier(build_fn=baseline_model) \n",
    "random = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=3, n_iter=3)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=10, verbose=0)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_allgram, IMDB_train_y = unison_shuffled_copies(train_allgram, IMDB_train_y)\n",
    "train_allgram = np.asarray(train_allgram)\n",
    "IMDB_train_y = np.asarray(IMDB_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 23s - loss: 0.5369 - acc: 0.8105 - val_loss: 0.4261 - val_acc: 0.8621\n",
      "Epoch 2/20\n",
      " - 24s - loss: 0.3368 - acc: 0.9002 - val_loss: 0.3334 - val_acc: 0.8869\n",
      "Epoch 3/20\n",
      " - 23s - loss: 0.2450 - acc: 0.9285 - val_loss: 0.2978 - val_acc: 0.8915\n",
      "Epoch 4/20\n",
      " - 23s - loss: 0.1906 - acc: 0.9449 - val_loss: 0.2812 - val_acc: 0.8956\n",
      "Epoch 5/20\n",
      " - 24s - loss: 0.1540 - acc: 0.9569 - val_loss: 0.2741 - val_acc: 0.8962\n",
      "Epoch 6/20\n",
      " - 24s - loss: 0.1261 - acc: 0.9665 - val_loss: 0.2735 - val_acc: 0.8957\n",
      "Epoch 7/20\n",
      " - 23s - loss: 0.1040 - acc: 0.9731 - val_loss: 0.2756 - val_acc: 0.8959\n",
      "Epoch 8/20\n",
      " - 23s - loss: 0.0863 - acc: 0.9790 - val_loss: 0.2815 - val_acc: 0.8959\n",
      "Epoch 9/20\n",
      " - 24s - loss: 0.0720 - acc: 0.9824 - val_loss: 0.2879 - val_acc: 0.8951\n",
      "Epoch 10/20\n",
      " - 24s - loss: 0.0597 - acc: 0.9857 - val_loss: 0.2969 - val_acc: 0.8957\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6399ab9b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train with best learning rate\n",
    "best_lr = random_result.best_params_['learn_rate']\n",
    "allgram_model_test = baseline_model(best_lr)\n",
    "\n",
    "# create early-stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=2, \n",
    "                          mode='auto', baseline=None, restore_best_weights=True)\n",
    "\n",
    "allgram_model_test.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.0500 - acc: 0.9854\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadhvi_mehta/anaconda3/lib/python3.5/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.0425 - acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe641a0e630>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train over both validation and train\n",
    "\n",
    "allgram_model_test.fit(train_allgram, IMDB_train_y, \n",
    "          validation_data=None, batch_size=200, epochs=10, verbose=1, callbacks=[earlystop], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allgram_model_test.save('rmsprop_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = allgram_model_test.evaluate(test_allgram, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.41618166644096377\n",
      "Test accuracy:  0.86836\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth Attempt: Change architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_shape=(30000,), activation='relu', kernel_regularizer=l2(1e-1)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 30s - loss: 7.2849 - acc: 0.7903 - val_loss: 0.9111 - val_acc: 0.8195\n",
      "Epoch 2/20\n",
      " - 26s - loss: 0.9164 - acc: 0.8289 - val_loss: 0.9520 - val_acc: 0.8382\n",
      "Epoch 3/20\n",
      " - 27s - loss: 0.9126 - acc: 0.8394 - val_loss: 0.9040 - val_acc: 0.8424\n",
      "Epoch 4/20\n",
      " - 26s - loss: 0.8716 - acc: 0.8511 - val_loss: 0.8277 - val_acc: 0.8534\n",
      "Epoch 5/20\n",
      " - 27s - loss: 0.8045 - acc: 0.8576 - val_loss: 0.7767 - val_acc: 0.8543\n",
      "Epoch 6/20\n",
      " - 26s - loss: 0.7469 - acc: 0.8703 - val_loss: 0.7942 - val_acc: 0.8563\n",
      "Epoch 7/20\n",
      " - 27s - loss: 0.6973 - acc: 0.8807 - val_loss: 0.7788 - val_acc: 0.8675\n",
      "Epoch 8/20\n",
      " - 26s - loss: 0.6691 - acc: 0.8874 - val_loss: 0.7280 - val_acc: 0.8651\n",
      "Epoch 9/20\n",
      " - 27s - loss: 0.6363 - acc: 0.8977 - val_loss: 0.7243 - val_acc: 0.8663\n",
      "Epoch 10/20\n",
      " - 27s - loss: 0.5791 - acc: 0.9073 - val_loss: 0.6943 - val_acc: 0.8676\n",
      "Epoch 11/20\n",
      " - 27s - loss: 0.5443 - acc: 0.9183 - val_loss: 0.7375 - val_acc: 0.8609\n",
      "Epoch 12/20\n",
      " - 26s - loss: 0.5300 - acc: 0.9170 - val_loss: 0.6753 - val_acc: 0.8674\n",
      "Epoch 13/20\n",
      " - 27s - loss: 0.5179 - acc: 0.9231 - val_loss: 0.6791 - val_acc: 0.8631\n",
      "Epoch 14/20\n",
      " - 26s - loss: 0.4806 - acc: 0.9272 - val_loss: 0.6557 - val_acc: 0.8654\n",
      "Epoch 15/20\n",
      " - 27s - loss: 0.4929 - acc: 0.9291 - val_loss: 0.6875 - val_acc: 0.8607\n",
      "Epoch 16/20\n",
      " - 27s - loss: 0.4783 - acc: 0.9337 - val_loss: 0.6568 - val_acc: 0.8640\n",
      "Epoch 17/20\n",
      " - 27s - loss: 0.4288 - acc: 0.9407 - val_loss: 0.6868 - val_acc: 0.8579\n",
      "Epoch 18/20\n",
      " - 27s - loss: 0.4545 - acc: 0.9366 - val_loss: 0.6859 - val_acc: 0.8611\n",
      "Epoch 19/20\n",
      " - 27s - loss: 0.4437 - acc: 0.9424 - val_loss: 0.6726 - val_acc: 0.8575\n",
      "Epoch 20/20\n",
      " - 27s - loss: 0.4350 - acc: 0.9409 - val_loss: 0.6958 - val_acc: 0.8609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe63f248be0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_layer_model = baseline_model()\n",
    "# train unigram model w/o stop words\n",
    "four_layer_model.fit(train_allgram[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 34s - loss: 0.4139 - acc: 0.9214\n",
      "Epoch 2/5\n",
      " - 34s - loss: 0.4186 - acc: 0.9235\n",
      "Epoch 3/5\n",
      " - 34s - loss: 0.4066 - acc: 0.9244\n",
      "Epoch 4/5\n",
      " - 34s - loss: 0.4120 - acc: 0.9237\n",
      "Epoch 5/5\n",
      " - 34s - loss: 0.4053 - acc: 0.9226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe63f468a90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on both validation and test\n",
    "four_layer_model.fit(train_allgram, IMDB_train_y, batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update regularization\n",
    "\n",
    "four_layer_model.layers[0].kernel_regularizer.l2 = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_layer_model.layers[0].kernel_regularizer.l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 34s - loss: 0.4001 - acc: 0.9257\n",
      "Epoch 2/5\n",
      " - 34s - loss: 0.3992 - acc: 0.9236\n",
      "Epoch 3/5\n",
      " - 34s - loss: 0.4041 - acc: 0.9219\n",
      "Epoch 4/5\n",
      " - 34s - loss: 0.3970 - acc: 0.9255\n",
      "Epoch 5/5\n",
      " - 34s - loss: 0.4055 - acc: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6288f2c50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on both validation and test\n",
    "four_layer_model.fit(train_allgram, IMDB_train_y, batch_size=200, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = four_layer_model.evaluate(test_allgram, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.41618166644096377\n",
      "Test accuracy:  0.86836\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 32s - loss: 7.3090 - acc: 0.7878 - val_loss: 0.7889 - val_acc: 0.8338\n",
      "Epoch 2/20\n",
      " - 27s - loss: 0.8378 - acc: 0.8275 - val_loss: 0.9127 - val_acc: 0.7980\n",
      "Epoch 3/20\n",
      " - 27s - loss: 0.7939 - acc: 0.8347 - val_loss: 0.7426 - val_acc: 0.8490\n",
      "Epoch 4/20\n",
      " - 27s - loss: 0.7824 - acc: 0.8432 - val_loss: 0.7718 - val_acc: 0.8377\n",
      "Epoch 5/20\n",
      " - 27s - loss: 0.7911 - acc: 0.8439 - val_loss: 0.7493 - val_acc: 0.8358\n",
      "Epoch 6/20\n",
      " - 27s - loss: 0.7444 - acc: 0.8633 - val_loss: 0.7569 - val_acc: 0.8563\n",
      "Epoch 7/20\n",
      " - 27s - loss: 0.7366 - acc: 0.8592 - val_loss: 0.7125 - val_acc: 0.8505\n",
      "Epoch 8/20\n",
      " - 27s - loss: 0.6861 - acc: 0.8679 - val_loss: 0.7203 - val_acc: 0.8556\n",
      "Epoch 9/20\n",
      " - 27s - loss: 0.6728 - acc: 0.8747 - val_loss: 0.7226 - val_acc: 0.8594\n",
      "Epoch 10/20\n",
      " - 27s - loss: 0.6419 - acc: 0.8781 - val_loss: 0.6485 - val_acc: 0.8708\n",
      "Epoch 11/20\n",
      " - 27s - loss: 0.6137 - acc: 0.8859 - val_loss: 0.6396 - val_acc: 0.8630\n",
      "Epoch 12/20\n",
      " - 28s - loss: 0.5782 - acc: 0.8864 - val_loss: 0.6903 - val_acc: 0.8591\n",
      "Epoch 13/20\n",
      " - 27s - loss: 0.5792 - acc: 0.8967 - val_loss: 0.6469 - val_acc: 0.8724\n",
      "Epoch 14/20\n",
      " - 27s - loss: 0.5463 - acc: 0.9027 - val_loss: 0.6228 - val_acc: 0.8714\n",
      "Epoch 15/20\n",
      " - 27s - loss: 0.5104 - acc: 0.9116 - val_loss: 0.6049 - val_acc: 0.8749\n",
      "Epoch 16/20\n",
      " - 27s - loss: 0.4927 - acc: 0.9185 - val_loss: 0.6406 - val_acc: 0.8706\n",
      "Epoch 17/20\n",
      " - 27s - loss: 0.4966 - acc: 0.9203 - val_loss: 0.6375 - val_acc: 0.8662\n",
      "Epoch 18/20\n",
      " - 27s - loss: 0.4696 - acc: 0.9276 - val_loss: 0.6071 - val_acc: 0.8734\n",
      "Epoch 19/20\n",
      " - 27s - loss: 0.4764 - acc: 0.9255 - val_loss: 0.6759 - val_acc: 0.8719\n",
      "Epoch 20/20\n",
      " - 27s - loss: 0.4530 - acc: 0.9345 - val_loss: 0.6308 - val_acc: 0.8631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1dd2de73c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_layer_model = baseline_model()\n",
    "# train unigram model w/ stop words\n",
    "four_layer_model.fit(train_allgram_w_sw[:15000], IMDB_train_y[:15000], \n",
    "          validation_data=(train_allgram_w_sw[15000:], IMDB_train_y[15000:]), batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 38s - loss: 0.5182 - acc: 0.8999\n",
      "Epoch 2/20\n",
      " - 37s - loss: 0.4849 - acc: 0.9070\n",
      "Epoch 3/20\n",
      " - 36s - loss: 0.4675 - acc: 0.9064\n",
      "Epoch 4/20\n",
      " - 36s - loss: 0.4618 - acc: 0.9092\n",
      "Epoch 5/20\n",
      " - 37s - loss: 0.4530 - acc: 0.9124\n",
      "Epoch 6/20\n",
      " - 36s - loss: 0.4568 - acc: 0.9098\n",
      "Epoch 7/20\n",
      " - 36s - loss: 0.4433 - acc: 0.9134\n",
      "Epoch 8/20\n",
      " - 36s - loss: 0.4508 - acc: 0.9125\n",
      "Epoch 9/20\n",
      " - 36s - loss: 0.4400 - acc: 0.9168\n",
      "Epoch 10/20\n",
      " - 37s - loss: 0.4372 - acc: 0.9172\n",
      "Epoch 11/20\n",
      " - 36s - loss: 0.4263 - acc: 0.9154\n",
      "Epoch 12/20\n",
      " - 36s - loss: 0.4196 - acc: 0.9187\n",
      "Epoch 13/20\n",
      " - 36s - loss: 0.4253 - acc: 0.9193\n",
      "Epoch 14/20\n",
      " - 36s - loss: 0.4168 - acc: 0.9155\n",
      "Epoch 15/20\n",
      " - 36s - loss: 0.4143 - acc: 0.9217\n",
      "Epoch 16/20\n",
      " - 36s - loss: 0.4212 - acc: 0.9182\n",
      "Epoch 17/20\n",
      " - 36s - loss: 0.4220 - acc: 0.9214\n",
      "Epoch 18/20\n",
      " - 36s - loss: 0.4192 - acc: 0.9227\n",
      "Epoch 19/20\n",
      " - 37s - loss: 0.4068 - acc: 0.9231\n",
      "Epoch 20/20\n",
      " - 36s - loss: 0.4159 - acc: 0.9208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1dcf4b5cc0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on both validation and test\n",
    "four_layer_model.fit(train_allgram_w_sw, IMDB_train_y, batch_size=200, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update regularization\n",
    "\n",
    "four_layer_model.layers[0].kernel_regularizer.l2 = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "four_layer_model.layers[0].kernel_regularizer.l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on both validation and test\n",
    "four_layer_model.fit(train_allgram, IMDB_train_y, batch_size=200, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply on test set to see performance:\n",
    "score = four_layer_model.evaluate(test_allgram_w_sw, IMDB_test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.5208094476318359\n",
      "Test accuracy:  0.87516\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
